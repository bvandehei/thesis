id,clssified,type,title,creation time,resolved time,priority,description,comments
HTTPCLIENT-569,BUG,BUG,"HttpState.clearCookies() should be synchronized",2006-02-14T07:17:55.000+0000,2007-04-22T07:11:16.891+0000,Minor,"The HttpState class has a clearCookies method that is not synchronized but
should be considering it modifies an ArrayList (which is unsynchronized). All
other methods which modify or read from the ArrayList are synchronized except
the clearCookies method. 

I stumbled upon this fact because a webapp I am working on that uses HttpClient
threw an IllegalArgumentException indicating that one of the cookies in the
array returned from HttpState.getCookies() was null, which shouldn't be
possible.  Upon further inspection and testing, the only possible option is that
the threadsafety hole left by the unsynchronized clearCookies method caused the
issue.","Created an attachment (id=17681)
Test case source code

The attached source code is what I used to confirm that there could be a
problem with the clearCookies method.  Every time I run it I get a null Cookie
after just a second or two.  Sure, it's contrived, but it is more of a proof of
concept than anything.","This is clearly a bug.

However it seems awkward to me why you wanted to clear cookies from a different
thread in the middle of other requests executing. Even if there is now no
exception thrown anymore HttpClient's behaviour is certainly not deterministic
in that case.","Created an attachment (id=17685)
Patch against 3.0 branch and trunk
","Patch away, Odi

Oleg","Patch committed.","(In reply to comment #2)
> This is clearly a bug.
> 
> However it seems awkward to me why you wanted to clear cookies from a different
> thread in the middle of other requests executing. Even if there is now no
> exception thrown anymore HttpClient's behaviour is certainly not deterministic
> in that case.

Agreed. When I saw someone else's code using the same HttpState object across
multiple threads, I immediately changed the code to use only one HttpState per
thread. Yes, their code was not written with threadsafety in mind, but
fortunately I was able to find that person's problem AND this bug and be part of
the solution for both."
HTTPCLIENT-386,BUG,BUG,"Catch SocketTimeoutException not InterruptedIOException",2004-10-09T05:48:53.000+0000,2007-04-22T07:10:52.559+0000,Major,"There are a couple of places where you're catching InterruptedIOException 
that should catch SocketTimeoutException instead.  For example, from 
HttpConnection:

    protected boolean isStale() {
        boolean isStale = true;
        if (isOpen) {
            // the connection is open, but now we have to see if we can 
read it
            // assume the connection is not stale.
            isStale = false;
            try {
                if (inputStream.available() == 0) {
                    try {
                        socket.setSoTimeout(1);
                        inputStream.mark(1);
                        int byteRead = inputStream.read();
                        if (byteRead == -1) {
                            // again - if the socket is reporting all data 
read,
                            // probably stale
                            isStale = true;
                        } else {
                            inputStream.reset();
                        }
                    } finally {
                        socket.setSoTimeout(this.params.getSoTimeout());
                    }
                }
            } catch (InterruptedIOException e) {
                // aha - the connection is NOT stale - continue on!

Here the catch of InterruptedIOException is intended to happen when 
inputStream.read() terminates due to the socket.setSoTimeout() time being 
reached.  However, it could also occur because Thread.interrupt() has been 
called, in which case "continue on" is not what should happen, instead, the 
request should terminate.

There are legitimate reasons why someone might want to interrupt the 
httpclient code, for example, httpclient does not provide a hard timeout on 
the total length of time a request may take, including connecting, sending 
the request, and receiving the complete response, so to enforce a hard 
timeout it is necessary to run the request in a worker thread and interrupt 
it if it hasn't completed before the timeout expires (the technique used in 
your TimeoutController class).

Note that SocketTimeoutException was added in 1.4.  For compatibility with 
older jdk versions, the code can catch InterruptedIOException and use 
getClass() to see whether it is a SocketTimeoutException.

There are probably other places in the code where InterruptedIOException is 
caught and interpreted as a socket timeout, and where Thread.interrupt() 
will not have the proper effect of causing the request to terminate ASAP, 
but I'm not familiar enough with the code to find them all.","Created an attachment (id=13011)
Patch (take 1)
","This should take care of the problem. Let me know what you think

Oleg","Thanks for the quick response.  Please give me some time to look things over 
thoroughly and get back to you.","The patch appears to be correct.  But I haven't had time to check through the 
entire execution path of the code I'm using.  And I haven't had a chance to 
contrive a test scenario.  But it does look good enough for alpha, thanks!","Folks, any objections to committing the patch?

Oleg","Looks good to me.

Mike","Patch committed.

Oleg"
HTTPCLIENT-302,BUG,BUG,"exception during writeRequest leaves the connection un-released",2003-12-10T04:20:47.000+0000,2007-04-22T07:10:38.033+0000,Major,"The execute method has the following (simplified) flow:
1) get connection
2) write request
3) read result
4) release connection.
The release in step 4 happens when the input is completely read, which works fine.
If an exception occurs between steps 1 and 2, the connection is also released
properly.
However, if an exception occurs during step 2, the connection is never released
back and the connection manager eventually runs out of connections.

The easiest way to test this is to make a simple subclass of PostMethod that
overrides the writeRequest method:

public class TestConnectionReleaseMethod extends PostMethod
{
    protected void writeRequest(HttpState state, HttpConnection conn) throws
IOException, HttpException
    {
         throw new IOException("for testing");
    }
}","Hhm, I/O exceptions thrown in writeRequest method are supposed to be treated as
recoverable, causing the writeRequest method to be retried without releasing the
connection. What kind of exception are you getting exactly? Besides, any idea if
CVS HEAD also exhibits this problem?

Oleg","The unfortunate reality with IOExceptions is that they can occur when you least
expect them. I ran into this while doing rigorous exception testing (see the
test code below).

The statement "writeRequest method are supposed to be treated as
recoverable" appears to be false: the method signature has IOException in it. It
is not possible to remove that either, because an IOException can truly occur
during the write. Of course, it is possible to change the method signature to
"throws HttpRecoverableException" and catch other exceptions and wrap them as
HttpRecoverableException. However, from the HTTP spec, a generic writeRequest is
*not* simply retriable (it is not considered idempotent for POST, PUT, etc; see
section 9.1 of the RFC). I would strongly discourage wrapping the IOException
inside writeRequest.
","> The statement "writeRequest method are supposed to be treated as
> recoverable" appears to be false: the method signature has IOException in it

Feel free to examine the source code and double-check. There is one situation I
know of, when I/O exceptions would not be rethrown as HttpRecoverableException,
that is, the connection is not known to have successfully completed a write
operation at least once. In all other cases, I/O exceptions are rethrown as
HttpRecoverableException (derived from IOException).

> However, from the HTTP spec, a generic writeRequest is *not* simply 
> retriable (it is not considered idempotent for POST, PUT, etc; see
> section 9.1 of the RFC). I would strongly discourage wrapping the IOException
> inside writeRequest

If understand the word of the spec correctly the section 9.1 postulates that
"... methods can also have the property of "idempotence" in that ... the
side-effects of N > 0 identical requests is the same as for a single request..."

HttpClient never automatically re-executes requests on a read operation failure.
Auto-recovery MAY takes place (if enabled) on a write operation (that is, the
request body never makes it to the server in its entirety). That guarantees that
there's at least one, but not more that one, successful request for a given
resource. Feel free to correct me if I am missing something. Besides,
auto-recovery can be customized through the use of MethodRetryHandler interface

Again, any idea under what circumstances the reported problem occurs? Do you
happen to know if CVS HEAD also exhibits the problem?

Oleg","This is an interesting discussion and I really appreciate the attention, time
and effort that goes into answering this.  

Let me answer the questions first:
> any idea under what circumstances the reported problem occurs? 
The problem has not (yet?) occured in running code. It was detected during
"exception testing". By "exception testing" I mean I put a line of code that says:

if (CAUSE_RANDOM_ERROR) if (Math.random() > ERROR_RATE) throw new
IOException("Random error, for testing only!");

anywhere an IO operation can occur. You'd be amazed the kinds of issue that come
to light when you do this. Essentially, it is a decent way to test all the error
handling code that people write but only execute under rare circumstances.

> Do you happen to know if CVS HEAD also exhibits the problem?
This is against RC2. The CVS codepath is quite different, but from reading the
source, I'm don't think the problem is fixed. Essentially, the connection is
only released if the response body is consumed. If the write failed, there is no
body to consume and therefore, the release won't occur.

> Feel free to examine the source code and double-check. There is one situation I
> know of, when I/O exceptions would not be rethrown as HttpRecoverableException,
> that is, the connection is not known to have successfully completed a write
> operation at least once. In all other cases, I/O exceptions are rethrown as
> HttpRecoverableException (derived from IOException).

From reading the code, it seems the outputstream is wrapped inside
WrappedOutputStream which rethrows any exceptions *inside its methods* as
recoverable. There are two problems with this approach. 
1) IOExceptions can (and do) occur outside the methods wrapped by
WrappedOutputStream. 2 examples: a) FilePart.java line 258 is reading a file.
That can throw an IOException. No amount of wrapping of the OutputStream will
catch this. b) A custom method that further wraps the stream (e.g. with an
ObjectOutputStream) may throw errors without ever touching the underlying stream
(e.g. NotSerializableException).
2) RuntimeExceptions have the same effect.


> HttpClient never automatically re-executes requests on a read operation failure.
> Auto-recovery MAY takes place (if enabled) on a write operation (that is, the
> request body never makes it to the server in its entirety). That guarantees that
> there's at least one, but not more that one, successful request for a given
> resource. Feel free to correct me if I am missing something. Besides,
> auto-recovery can be customized through the use of MethodRetryHandler interface

Thanks for the clarification. You still have to be extremely careful if you
enable auto recovery on write. Just because the write failed somewhere, doesn't
mean the server didn't do anything. Take the simple case of a multi-part mime
message consisting of several files (to be saved on the server). If the last
file being sent dies with an IOException (e.g. the network drive it was on went
to lala land), the server very likely already received and processed all the
files prior to that. Resending those files can cause major issues (for example,
the server may refuse to overwrite an existing file,  a batch process waiting
for a file may rerun some transactions, etc).

How about this fix: add
                catch (IOException e) {
                    releaseConnection = true;
                    throw e;
                } catch (RuntimeException e) {
                    releaseConnection = true;
                    throw e;
                }
to the last try clause in HttpMethodDirector#executeWithRetry ?

Thanks
Moh

","> if (CAUSE_RANDOM_ERROR) if (Math.random() > ERROR_RATE) throw new
> IOException("Random error, for testing only!");

OK. I see.

> From reading the code, it seems the outputstream is wrapped 
> insideWrappedOutputStream which rethrows any exceptions *inside its methods* 
> asrecoverable. There are two problems with this approach. 

Mohammad, actually that is that way it is supposed to be. IOException thrown
when retrieving request content or runtime exceptions are not recoverable HTTP
transport exceptions and should not be treated as such 

> Thanks for the clarification. You still have to be extremely careful if you
> enable auto recovery on write.

Agreed. I personally am not in favour of having auth-recovery activated per
default, but according to the feedback we were getting from our users the
majority did not appear to share that conviction.

> How about this fix: add
>                 catch (IOException e) {
>                     releaseConnection = true;
>                     throw e;
>                 } catch (RuntimeException e) {
>                     releaseConnection = true;
>                     throw e;
>                 }
> to the last try clause in HttpMethodDirector#executeWithRetry ?

That can be done. I would not like to change 2.0 branch, though, for the
following reason: the invocation of HttpClient#execute(HttpMethod) MUST be
followed by HttpMethod#releaseconnection regardless of the outcome (preferably
by calling it in the finally clause). This is a part of HttpClient API contract.
So, personally do not see this bug serious enough to warrant modification of
HttpClient 2.0 which is the release candidate phase.

Oleg","Created an attachment (id=9607)
Test case and 2.0 patch
","Here's a test case and a possible fix for 2.0.  I'm not sure this is exactly what we want, but it's a 
start.

Mike","i believe that this has something to do with the fact, that the connection would
have to be closed because HttpClient cannot finish the request due to the lack
of data.
the anoying thing for me was, that HttpClient tries to finish a HTTP-request if
one calls releaseConnection(). finishing a HTTP-request ment downloading the
rest of the requested data for me. in this case this behaviour is even more fatal.

this is a serious issue since it causes connections to idle around if this error
happens - if i understand everything correctly.","Same condition occurs on a RuntimeException. Mike's patch can easily be updated
to take care of it.

Thanks
Moh
","Created an attachment (id=9617)
Possible patch 2
","Okay.  Here it is.  This one releases and closes the connection in the event of an unrecoverable 
exception in HttpMethodBase.processRequest().  Let's give it a try and see how it holds up.

Mike","+1 to be committed.

Oleg","Patch applied to 2.0.

Mike","Created an attachment (id=9904)
Patch against HEAD (take 1)
","Mike's patch ported to CVS HEAD. Please review","Looks good.

Mike","Patch committed to CVS HEAD. 
Oleg."
HTTPCLIENT-104,IMPROVEMENT,BUG,"Incorrect debug message in HttpMethodBase",2002-09-12T08:57:01.000+0000,2007-04-22T07:10:07.553+0000,Major,"HttpMethodBase.addContentLengthRequestHeader has the wrong debug message.  See
attached patch.","Created an attachment (id=3026)
Patch to repair addContentLengthRequestHeader debug message
","Patch applied."
HTTPCLIENT-85,BUG,BUG,"Host request header does not contain port",2002-07-27T03:54:06.000+0000,2007-04-22T07:10:04.951+0000,Major,"The Host request header is always added with just the hostname used for the 
connection.  If the port is different than 80 it needs to be included as well, 
with a colon separating it from the hostname.  This problem is especially 
apparent when you use the httpclient to connect to tomcat 4 and then use 
HttpUtils to create a full URL representing the request.  HttpUtils pulls the 
host and port from the Host header.  When commons-httpclient is used HttpUtils 
never includes the port since it was never in the Host header.","This behaviour has changed slightly since alpha1.  The current behaviour is as
follows: 
    if (!isIpAddress(host)) {
        if (port == 80) {
            setRequestHeader("Host", host);
        } else {
            setRequestHeader("Host", host + ":" + port);
        }
    } else {
        setRequestHeader("Host", "");
    }

So if the host is an actual hostname, and is not port 80, then the port will be
concatenated to the hostname seperated with a colon.

If the host is an ipaddress, then the host header is added but with a blank
value.

<cite href="http://www.ietf.org/rfc/rfc2616.txt">
   A client MUST include a Host header field in all HTTP/1.1 request
   messages . If the requested URI does not include an Internet host
   name for the service being requested, then the Host header field MUST
   be given with an empty value. An HTTP/1.1 proxy MUST ensure that any
   request message it forwards does contain an appropriate Host header
   field that identifies the service being requested by the proxy. All
   Internet-based HTTP/1.1 servers MUST respond with a 400 (Bad Request)
   status code to any HTTP/1.1 request message which lacks a Host header
   field.
</cite>
","Marked as fixed by mistake.  Awaiting Bruce Duncan to acknowledge the previous
comment.","The existing fix still have a problem: it doesn't handle the default port 
number correctly. The default port number is 80 for http and 443 for https.

The following is a fix for this problem:


    protected void addHostRequestHeader(HttpState state, HttpConnection conn) 
throws IOException, HttpException {
        // Per 19.6.1.1 of RFC 2616, it is legal for HTTP/1.0 based
        // applications to send the Host request-header.
        // TODO: Add the ability to disable the sending of this header for 
HTTP/1.0 requests.

        String host = conn.getHost();
        int port = conn.getPort();

        if (!requestHeaders.containsKey("host") && !isIpAddress(host)) {
            if(conn.isSecure()) {
                if(443 != port) {
                    host += ":" + port;
                }
            }
            else {
                if(80 != port) {
                    host += ":" + port;
                }
            }
            setRequestHeader("Host", host);
        }
    }","Created an attachment (id=2579)
Fix
","Patch applied.  Test cases added and passed to reflect the new logic."
HTTPCLIENT-196,BUG,BUG,"httpClient failed to reconnect after keep-alive connection timed out",2003-04-23T03:01:41.000+0000,2007-04-22T07:10:20.608+0000,Critical,"Description:

When using httpClient with https tunnelling througha proxy server, after keep-
alive connection timed out on server side.  The httpClient code was unable to 
establish the connection again.

Cause:

The HttpMethodBase.processRequest's retry loop retries the connection without 
going through the "CONNECT" request to the proxy server.  Our proxy server 
returns 407 error code.  In case of tunnelling connection, proper reconnect 
should be done by first doing the "CONNECT" sequence to get authenticated 
throught the proxy.

Temp fix and Work around:

We implemented some work around to do the retry from the application layer.  In 
order to detect the situation, we have to rely on the error message contained 
in the HttpRecoverableException.  We are checking the text "Connection aborted 
by peer: socket write error".  We also have to modify the HttpMethodBase code 
to throw the HttpRecoverableException out to the application.","Created an attachment (id=5963)
Temp fix for checking "Connection aborted by peer: socket write error" and throw exception
","HttpClient does not support reusing tunneled HTTPS connections.  This is a known
problem.  This problem was "fixed" post alpha-3 so you will need to get a
nightly build for this one.

Mike","Mike,

I have the latest code from nightly build now.  It looks like that the 
tunnelled https connection is now being closed each time.  We definitely need 
keep-alive in our application (connecting each time would be too slow for our 
app).  Will the final release of httpClient support tunnelling https connection?","Bin, the wire log would be very helpful

Oleg ","Created an attachment (id=6055)
wire log showing each POST follows CONNECT
","Oleg,

The wire log was chopped off from the top.  But it has enough transactions in 
it and it shows that each time, the complete "CONNECT"/"POST" sequence is 
performed.  That is due to the httpClient code decides to close the tunnelled 
connection each time.","Yes, as mentioned in some previous emails HttpClient does not support tunneled
HTTPS presistence.  This is due to a design flaw that keeps HttpClient from
correctly re-establishing a connection after timeout.

Mike","Mike,
This is not about connection timeout. According to the log tunneled connection
gets closed after each request/response exchange. I am currently trying to
reproduce the problem on my development system.

Oleg","Tunneled HTTPS connections are setup so that they only get used once.  This
appears to be what is happening.  After the NTLM request/response exchange the
method is executed and the response is read.  At this point
HttpConnection.releaseConnection() is called and it explicitly closes itself
because is tunneled HTTPS.

Mike","I thought the only problem was that HttpClient due to the current design could
not properly retry requests over tunneled connection (as CONNECT can't be
cleanly re-issued). But what's the reason for always closing tunneled connections?

Oleg ","This purpose was to "fix" this problem by not allowing these connections to be
reused.  We decided "I believe in the IRC meeting" that this was the way to go.
 The reason being that since tunneled+HTTPS connections cannot be reused
reliably they should not be reused.  

The main problem case WAS when a method got a previously used connection (that
had timed out) and tried to use it.  This would cause the method to fail, with
the only feasable solution being to retry in HttpClient.  Since we were waiting
to push the retry logic into HttpClient this was also put off.  Thus the fairly
lousy solution.

The reason I say "WAS" above is that I think we can fix this now.  I think, now
that we have the ability to test for stale connections, this can be handled by
HttpClient.  HttpClient is currently calling HttpConnection.isOpen() in
execute(), which should preemptively take care of stale tunneled+HTTPS
connections.  I believe that if we remove the force close in
HttpConnection.releaseConnection() we may have a viable solution.  At least for
people who are using HttpClient (not the connections directly) and also have JRE
1.4 or better.

Mike","Sorry, Mike. You are right. I guess I am getting old. 

It's your call if it is safe to relax somewhat the restriction on tunnelled
connection pooling.

Oleg
PS: We HAVE GOT to move past 2.0 as soon as possible.","No worries.  Things have been getting pretty complicated lately.  I am having
trouble keeping track of all of the various HttpClient nuances.  

We definitely need to push on past beta-1 very soon.  This interim period has
been taking way too long.

I will make a few tests without the force close just to make sure that it works.
 My only worry is for the people who are using connections directly.  It will
work for them, assuming that isOpen() is being called before the method is executed.

Laura, do you have any thoughts?

Mike","Created an attachment (id=6061)
remove force connection close patch
","The above patch removes the force close in HttpConnection.releaseConnection()
when using tunneled+HTTPS connections.  As expected, this correctly allows
persistent connections when using JRE 1.4 or later.  As previously discovered
pre 1.4 implementations of JSSE do not correctly handle the isStale() read test.

Bin, I don't know how useful this will be for you as it appears you are using
1.3.1.  Please give it a try though, just to be sure.

Laura, I'm singling you out just because I know your app uses connections
directly, I hope you don't mind:)  I would appreciate any feedback you might
have, assuming that you are using tunneled HTTPS.

Thanks,

Mike","Mike,
I tested the patch a bit. It works fine with JDK 1.4 for me (and does not with
1.2 which is expected). Once we get Laura's consent I'd call it the end of the
story. This is as good as it gets for 2.0 release in my opinion.

Oleg","Releated issue with MethodRetryHandler:

We are trying to use the MethodRetryHandler to control when the httpClient 
should retry after HttpRecoverableException.  We run into two issues:
1. One of our criteria of retrying depends on if the connection is tunnelled.  
We will need to have access to the HttpConnection object to know that (using 
isSecure/isProxied combination).  Are there any other ways to get that 
information from HttpMethod?  If not, can httpClient code pass the data to 
retryMethod?
2. It would be mroe convenient to have a base class implementing the 
MethodRetryHandler so app can call the super for cases it doe snto want to 
override.","Sounds reasonable.  I will add this tonight.

Mike","Created an attachment (id=6113)
retry handler patch
","This patch extracts the default retry handler to a new class and adds the
connection as a new parameter.

Mike","Looks good to me.

Oleg","Patch applied."
HTTPCLIENT-697,IMPROVEMENT,BUG,"Http Client give sme message when proxy/http endpoint is down",2007-10-24T01:02:49.119+0000,2007-10-28T16:57:04.649+0000,Minor,"Whether Http sever endpoint is down or the proxy server is down we get the same stack trace as:

java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:518)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.commons.httpclient.protocol.ReflectionSocketFactory.createSocket(ReflectionSocketFactory.java:139)
	at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:124)
	at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:706)
	at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1321)
	at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:386)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)
	at com.approuter.module.http.protocol.HttpTransportSender.perform(HttpTransportSender.java:214)
	at 


It will be good if we can get information whether the proxy was down or the Http endpoint.

","We could subclass java.net.ConnectException and add some fields like the HostConfiguration. Then catch, wrap, throw. If you're esoteric, you may argue that this change may break existing users that serialize the exception and lack the class on the deserializing side. Not sure if we should change that in 3.x.","Makes sense to me, Odi

Oleg","Here's the patch for the proposed change. Odi, please review.

Oleg","Perfect.","Patch checked in.

Oleg"
HTTPCLIENT-477,RFE,BUG,"There is no way to specify a different auth scheme priority for host and proxy",2005-06-30T06:33:52.000+0000,2007-10-18T14:48:34.257+0000,Major,"Using HttpClient 3.0 rc2, you cannot authenticate to a site using Basic
Autentication and to a proxy server using NTLM authentication.

When you indicate a prefference to use NTLM over Basic authentication the
authentication will fail when it tries to authenticate NTML to the Proxy and to
the Site. If you indicate Basic, then NTLM authentication order the Basic
authentication will fail when used for the Proxy (since basic authentication
can't send the domain name it fails).

The email thread from the discussion group is pasted below for refference.

==============================================================
==============================================================

Hi all,
I am trying to authenticate to a server via a proxy which also requires
authentication. It seems that I can get either the proxy authentication to work
OR the site authentication to work, but not both.

Both seem to work independently when I set the credentials (or proxy
credentials) using NTCredentials (e.g. if I connect to the site from a network
not using a proxy I can get it to work, and I can authenticate to the proxy only
to get a 401 authentication failed from the server when using the proxy).

I read in the Authentication tutorial that you can't authenticate using NTLM to
both the proxy and site, so I'm trying various combinations of authentication,
but I can't find any documentation that specifically covers this case and I feel
like I'm just taking stabs in the dark right now.

If anyone can point me in the direction of the light at the end of the tunnel
I'd really appreciate it.

Thanks,
David

----------------

On Wed, Jun 29, 2005 at 09:53:07AM -0700, David Parks wrote:
> Hi all,
> I am trying to authenticate to a server via a proxy which also requires
authentication. It seems that I can get either the proxy authentication to work
OR the site authentication to work, but not both.
> 
> Both seem to work independently when I set the credentials (or proxy
credentials) using NTCredentials (e.g. if I connect to the site from a network
not using a proxy I can get it to work, and I can authenticate to the proxy only
to get a 401 authentication failed from the server when using the proxy).
> 
> I read in the Authentication tutorial that you can't authenticate using NTLM
to both the proxy and site, so I'm trying various combinations of
authentication, but I can't find any documentation that specifically covers this
case and I feel like I'm just taking stabs in the dark right now.

David,

You _really_ can't use NTLM to authenticate with the proxy and the
target host at the same, due to the nature of this authentication
scheme. Really. That was not a joke.

Please consider using one of the following combinations instead:

(1) BASIC proxy + NTLM host if both the clent and the proxy are within a
trusted network segment

(2) NTLM proxy + SSL + BASIC host

Both combinations should provide an adequate (or better in the latter case)
security

Hope this helps

Oleg

> 
> If anyone can point me in the direction of the light at the end of the tunnel
I'd really appreciate it.
> 
> Thanks,
> David
> 
> 

-------------------

Thanks for the reply Oleg. This is what I figured, but I cannot see how to use
different authentication schemes for the Proxy vs. the Site authentication
challenge.

I tried adding the code suggested in the Authentication tutorial:

        List authPrefs = new ArrayList(2);
        authPrefs.add(AuthPolicy.DIGEST);
        authPrefs.add(AuthPolicy.BASIC);
        authPrefs.add(AuthPolicy.NTLM);
         This will exclude the NTLM authentication scheme
        httpclient.getParams().setParameter(AuthPolicy.AUTH_SCHEME_PRIORITY,
authPrefs);

I got a message stating that it was attempting BASIC authentication for the
Proxy and that it failed (probably because the domain doesn't get passed I
guess). So my thought is that I need NTLM for the proxy authentication and Basic
will work for the site authentication.

The question I am then working on is how to direct the HttpClient to select that
order of authentication methods. If I let it take NTLM as the preffered
authentication method then it will try to authenticate both challenges with NTLM.

I sure there is just some little detail I'm missing here somewhere, it's just
hard to find it.

Thanks a lot!
David

------------------

David,

I see the problem. This will require a patch and a new parameter.
Luckily the preference API introduced in HttpClient 3.0 allows up to add
parameters quite easily. Please file a feature request with Bugzilla
ASAP and I'll do my best to hack up a patch before I leave for holidays
(that is Friday, July 1st)

Oleg


--------------

Hi Oleg, thanks, I'll put that request in today.
This helps a lot, at least I know I'm on the right path now.

I am attempting to devise a workaround for this by handling the authentication
manually (setDoAuthentication(false)).

When I see a 401 error I am processing a basic authentication with the site
credentials, when I see a 407 error I want to process an NTLM authentication
with the proxy credentials.

To that end I have the following code that runs after
httpclient.execute(getmethod) executes. The code below works perfectly for the
basic authentication (when the proxy is not in the picture).

In looking up the Handshake of the NTLM authentication I see that I have a
problem with the code below since the handshake includes 2 challenge and
authorization steps before the authentication succeeds. I'm not clear how I
could manually authenticate the NTLM response. I would expect the NTLMScheme
class to contain a Type 1 and Type 3 authenticate() method for processing both
challenge responses. Is there another way of processing the NTLM authentication
after receiving the initial authentication challenge from the server?

        //Check for Proxy or Site authentication
        if(getmethod.getStatusCode() == 401){
            //Authenticate to the site using Basic authentication.
            BasicScheme basicscheme = new BasicScheme();
            String basic_auth_string = basicscheme.authenticate(new
NTCredentials("cwftp", "664A754c", "", ""), getmethod);
            Header basic_auth_header = new Header("Authorization",
basic_auth_string);
            getmethod.addRequestHeader(basic_auth_header);
            try{
                httpclient.executeMethod(getmethod);
            }catch(Exception e){
                logger.log(Level.SEVERE, "ack!!!!", e);
            }
            return getmethod;
       }else if(getmethod.getStatusCode() == 407){
            //Authenticate to the site using Basic authentication
            NTLMScheme ntlmscheme = new NTLMScheme();
            String basic_auth_string = ntlmscheme.authenticate(new
NTCredentials("00mercbac", "!@SAMmerc2004", "simproxy", "CFC"), getmethod);
            Header basic_auth_header = new Header("Authorization",
basic_auth_string);
            getmethod.addRequestHeader(basic_auth_header);
            try{
                httpclient.executeMethod(getmethod);
            }catch(Exception e){
                logger.log(Level.SEVERE, "ack!!!!", e);
            }
            return getmethod;
       }


Thanks,
David","Will require a new parameter and is likely to require more changes in the auth
code than I would be comfortable with so late in the release process. Pushed
back to 3.1

Oleg","I do not see a way to fix the problem cleanly in 3.1. I suggest we deal with it in 4.0 

Oleg","Httpclient 4.0 now uses distinct instances of the authentication handler interface to authenticate against target and proxy hosts. This allows for injection of a custom handler responsible for authentication with just one type of hosts.

Oleg"
HTTPCLIENT-1054,IMPROVEMENT,IMPROVEMENT,"HTTPClient per default relentlessly spams to stderr",2011-02-07T12:57:23.247+0000,2011-02-07T20:06:20.050+0000,Minor,"HTTPClient relentlessly spams to stderr when including it into a project via maven. This is not a decent default behaviour for a libary. Libaries should, per default, communicate their internal state solely and adequatly via their API and let it be up to the application to react to that state (logging it is one such reaction). From some replies to tickets in the same vain I can see that this is perhaps a sensitive topic as some see logging to be a core concern of HTTPClient. I do agree it's helpful as a debugging tool but as such it needs to be opt-in. As a standard error output, the logging of HTTPClient is absolutely useless because it does not and can not describe what the application is trying to do.

Why this improvement when there is a way to disable HTTClient logging (in fact, there seem to be many ways ... always a bad sign ..)?

Do a google search for: httpclient "console spam"
204 hit for this harsh phrasing alone. Search this phrase for any other libary you like to use and compare the number of hits. Ask youself, how often have you seen the java standard libary write to stdout or stderr?

Personally, I tried to disable it via JDK14 getLogger("org.apache").setLevel(Level.OFF)  which wouldn't work and now am using a solution I found on Stackoverflow which is:

System.setProperty("org.apache.commons.logging.Log", "org.apache.commons.logging.impl.NoOpLog"); }

The problem I have is that I include this lib and suddently my console is useless because httpclient is all over it (writing a system monitor ...). I have to search google to find a solution (http://hc.apache.org/httpcomponents-client-ga/logging.html does not tell you how to turn logging off ...) and the logical one "turn of the JDK logger" does not work right away.

It's really a matter of following the principal of least suprise (a libary is not expected to write to the console which is the observable default behaviour of HTTPClient) and the principal of separation of concerns (logging is a concern for applications and not for libaries).

Following at least one of these would substantially increase the joy of working with the HTTPClient libary.

","Which version of HttpClient is this issue for? 

Commons HttpClient 3.1 does indeed have a tendency of abusing INFO priority logs for logging often irrelevant details. This problem has long been solved in the 4.x series. 

Oleg","Hello Oleg,

thanks for your response. Yes, I'm using 3.1 which I just assumed to be the latest.

Kind Regards,
Wulf"
HTTPCLIENT-1030,RFE,RFE,"Implement "ignoreCookies" CookieSpec",2010-12-03T21:24:44.675+0000,2010-12-04T21:18:22.214+0000,Major,"It would be useful to Implement an "ignoreCookies" CookieSpec, as was done in Commons HC 3.1

This should be registered by DefaultHttpClient.createCookieSpecRegistry().

Patch to follow.","Hi Sebastian

One can completely disable cookie processing by removing two protocol interceptors from the protocol processing chain (RequestAddCookies and ResponseProcessCookies). However, if you think availability of "ignoreCookies" cookie spec would ease migration from 3.1 to 4.x, please by all of means go ahead and commit the patch.

Oleg","Thanks. 
Having an ignore option will make it easier for JMeter which currently uses the ignoreSpec to suppress cookie handling; I imagine other applications may do the same."
HTTPCLIENT-553,DOCUMENTATION,BUG,"JavaDoc getConnection methods in Connection Managers",2006-01-14T09:54:44.000+0000,2006-06-11T05:08:36.000+0000,Major,"The JavaDoc for the getConnection() methods in the Simple and MultiThreaded
Connection managers is taken from the interface, and so is too generic.

The Javadoc for the doGetConnection() method in the MultiThreaded manager is
fine, but is not visible in the JavaDoc

The Simple Mangager JavaDoc could likewise be improved

[I hope to provide patches shortly]","Patch (take 1). Please review.

Oleg","Sebastian, does the patch solve the problem for you? Is it okay to commit?

Oleg","That looks fine.","Patch checked in

Oleg"
HTTPCLIENT-30,RFE,BUG,"should allow receiving secure cookies from non-secure chanel",2002-04-19T06:42:47.000+0000,2006-05-15T21:44:46.000+0000,Major,"Currently, httpclient will throw an exception if a secure cookie is received 
from a non-secure chanel. Although RFC doesn't specify explicitly on if the 
client should allow receiving secure cookie from non-secure channel, the 
default setting in browser seems to allow it.

Try the following link in IE:

http://www.snapfish.com

The default cookie policy in httpclient should be the same.","RFC 2109 does not prohibit receiving secure cookies over and insecure channel 
(See section 4.2.2).  Thus, HttpClient should not throw an an exception in this 
case.  

The specification *does* gives us (the client) the leeway to decided when we 
will send 'secure' cookies back to the origin server.  HttpClient will sill 
only add secure cookies to a Cookie header if the connection is secure."
HTTPCLIENT-452,BUG,BUG,"DateUtil.formatDate() uses default timezone instead of GMT",2005-04-23T03:11:00.000+0000,2007-04-22T07:11:00.841+0000,Major,"DateUtil.formatDate() uses default timezone instead of GMT.  In section 3.3.1,
RFC 2616 states:  "All HTTP date/time stamps MUST be represented in Greenwich
Mean Time (GMT), without exception."

To reproduce, run the following snippet:

   public static void main(String[] args) {
      TimeZone tz = TimeZone.getTimeZone("GMT");
      GregorianCalendar gc = new GregorianCalendar(tz);
      gc.set(1900 + 104, GregorianCalendar.JANUARY, 1, 0, 0, 0);
      System.out.println(DateUtil.formatDate(gc.getTime()));
      
   }

Expected result:
Thu, 01 Jan 2004 00:00:00 GMT

Actual result (if your default timezone is PST):
Wed, 31 Dec 2003 16:00:00 PST","Created an attachment (id=14796)
Proposed  patch

Simple one-liner patch.","Looks good to me.  Some test cases would be nice...

Mike","Created an attachment (id=14807)
Patch (take 2)

How about this minor optimization? Anyone aware of any threading issues related
to TimeZone class?

Oleg","Looks fine to me.  I'm not aware of any threading issues.  The Javadocs seem pretty silent on the issue.

Mike","Looks good. I have used Date, Calendar and TimeZone extensively during the last
half year while developing a calendaring webapp. The only thing to be careful
about is that a TimeZone is mutable. It seems completely read-only thread safe
though.","Patch committed.

Oleg"
HTTPCLIENT-824,TASK,TASK,"Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient",2009-02-07T13:21:15.321+0000,2009-10-15T11:15:17.507+0000,Major,"Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient and replace with thread-safe implementations where necessary.

Oleg","I reviewed the code and found the following:

(1) HttpClient correctly synchronizes access to its ProtocolProcessor instance variable. It also makes a copy of it before passing it the request director, so the master copy can be safely mutated while current requests are being executed. No problem here. 

(2) Things are a bit messy with HttpParams. BasicHttpParams classes is used all over the place. Decorating those with a non-public thread-safe wrapper inside HttpClient does not really help as the user can still mutate its state using the original reference. The problem can be solved only by introducing a public thread-safe implementation of HttpParams, which we cannot do until 4.1

Oleg","Fixed in SVN trunk

Oleg"
HTTPCLIENT-286,BUG,IMPROVEMENT,"Manually set 'Cookie' & 'Authorization' headers get discarded",2003-10-24T04:52:06.000+0000,2007-04-22T07:10:35.480+0000,Minor,"HttpClient discards all the 'Cookie' & 'Authorization' headers including those
manually set when populating request header collection with automatically
generated headers.","Created an attachment (id=8711)
Patch (take 1)
","The patch should take care of the problem. Feedback welcome.

Oleg","Hello Oleg,

I have just taken a look at it. In combination with pluggable cookie policies,
this patch provides everything I would need. Cookies can be set manually, with
or without being extended by the cookies from the HttpState. Resolving clashes
between manually set cookies and those in the state is the responsibility of
whom who sets cookies manually. And someone who wants his cookie header to be
removed automatically shouldn't set it in the first place :-)

No, wait, there is one thing:  RFC 2965 in section 3.3.4 (last paragraph before
the note) specifies that cookies shall be sent in a defined order, those with
more specific paths preceeding those with less specific paths.
Considering the fuss of parsing manually set cookie headers, I wouldn't want
this to be implemented by the HTTP Client. But that should at least be pointed
out somewhere in the JavaDocs. In HttpMethod.{set|add}RequestHeader?

cheers,
  Roland
","Looks good to me.

Mike","Patch committed.

Oleg","Funny,

When I reported this bug, I was told this would never get fixed.

Glad to see it's fixed.

-Eric"
HTTPCLIENT-323,RFE,IMPROVEMENT,"GetMethod.getResponseBodyAsStream() .available() could return content-length",2004-03-02T22:06:49.000+0000,2007-04-22T07:10:41.587+0000,Minor,"It would be nice if the InputStream returned from
GetMethod.getResponseBodyAsStream() could override the available()
method to return the content-length of the requested URL.  This would
make things like ProgressMonitorInputStream useful for monitoring the
progress of a download.  Here is a code snippet:


/**
 * supply a hard-coded value for available() method.
 */
class FixedInputStream extends FilterInputStream {
  private int contentLength;

  public FixedInputStream(InputStream is,
              int contentLength) {
    super(is);
    this.contentLength = contentLength;
  }

  public int available() throws IOException {
    return contentLength;
  }
} 



Also, somewhat related to this request, could
GetMethod.getResponseContentLength() must be made public?  Is there a
good reason for it to be protected?  I had to extend GetMethod and
implement a public getResponseContentLength() in order to feed that
value to my FixedInputStream.

Thanks for your time.","The available()-Methode should return the amout of data which can be read()
without blocking. That is _not_ the whole content-length, but the amount of data
that is available in HttpClient's internal buffers.","George,
I do not think we should violate standard Java API even in such a subtle manner.
The purpose of InputStream#available() method is different and we should not get
too creative about Java API. As to HttpMethodBase#getResponseContentLength()
being protected, there is really no particular reason. I think we can safely
make the method public. Objections, anyone?

Oleg","Created an attachment (id=10708)
Patch
","> I do not think we should violate standard Java API even in such a
> subtle manner.  The purpose of InputStream#available() method is
> different and we should not get too creative about Java API.

I agree that the available() method is not documented to mean "length
of stream", however even Java's own ProgressMonitorInputStream uses it
this way.  Gosling wrote that class, and in it he sets size =
available().  If available() only returns the amount of data currently
buffered, the ProgressMonitor does nothing useful.  I guess it would
have been nice if the InputStream base class had a "length()" method
as well.  

Anyway, I can implement the behavior by writing an extension class, so
no need for you to violate the API in HttpClient.  Feel free to close
this enhancement request, and thanks for your consideration.","I agree with Oleg.  Making available() return the content length, though useful, would be pretty non-
standard.  Making getResponseContentLength() public is the way to go.

Mike","George,

Even Gossling can write sub-optimal code. We all know there is some very bad
code in the Java Standard API :-) InputStream::available() is clearly documented
as "Returns the number of bytes that can be read (or skipped over) from this
input stream without blocking by the next caller of a method for this input
stream." Not following this contract is one bad thing. The user relying on us to
follow a different contract than the original method is even worse.
Also the nature of a stream allows for an infinite stream of data. I guess that
this was the reason that the Java API provides no way of figuring out the length
of a stream. And it is the same reason for us to provide this completely
optional piece of information with a supplementary method called
getResponseContentLength(). It can even return -1 if the content length is unknown.","> And it is the same reason for us to provide this completely optional
> piece of information with a supplementary method called
> getResponseContentLength(). It can even return -1 if the content
> length is unknown.

If that method could be made public, that would be great, thanks!
","Patch applied to the CVS HEAD

Oleg"
HTTPCLIENT-960,BUG,BUG,"HttpMultipart doesn't generate Content-Type part header in mode BROWSER_COMPATIBLE",2010-06-30T13:12:16.253+0000,2010-09-13T18:56:56.698+0000,Major,"Browsers (tested with Firefox 3.6 and IE6) send a Content-Type header for file parts, what org.apache.http.entity.mime.HttpMultipart doesn't do in BROWSER_COMPATIBLE mode.


Example:

-----------------------------142889018617181602061216500409

Content-Disposition: form-data; name="myFileFieldName2"; filename="webtest.png"

Content-Type: image/png


In HtmlUnit we wil subclass HttpEntity and MultipartEntity to fix this problem.","Subclassing wasn't possible. Rather than to copy and fix HttpEntity and MultipartEntity, we now use a hack: we access MultipartEntity's private field multipart and change the CONTENT_DISPOSITION field value to contain as well \r\nContent-Type.... It's not nice but...","Fixed in SVN trunk. Please review / test.

Oleg"
HTTPCLIENT-813,BUG,BUG,"HttpClient throws NPE on Invalid Port when used with MultiThreadedHttpConnectionManager",2009-01-07T16:56:28.760+0000,2009-02-14T16:47:16.707+0000,Major,"The HttpClient throws NullPointerException in the main thread when an invalid port (like 80001) is used in the URL. An IllegalArgumentException is thrown in TimeoutGuard thread.
 
Exception in thread "Timeout guard" java.lang.IllegalArgumentException: port out of range:80001
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)
	at java.net.Socket.<init>(Socket.java:240)
	at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
	at org.apache.commons.httpclient.protocol.ControllerThreadSocketFactory$1.doit(ControllerThreadSocketFactory.java:91)
	at org.apache.commons.httpclient.protocol.ControllerThreadSocketFactory$SocketTask.run(ControllerThreadSocketFactory.java:158)
	at java.lang.Thread.run(Thread.java:613)
Exception in thread "main" java.lang.NullPointerException
	at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:721)
	at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
	at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
	at com.aol.test.HttpTest$PoolingHttpConnector.doGet(HttpTest.java:47)
	at com.aol.test.HttpTest.main(HttpTest.java:17)

It should throw a checked exception in main thread so caller can handle the error condition more gracefully.

The test program is attached. This is caused by a race condition and it's not always reproducible. Running in debugger shows a different behavior.

package com.aol.test;

import java.io.IOException;

import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.HttpStatus;
import org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;
import org.apache.commons.httpclient.methods.GetMethod;
import org.apache.commons.httpclient.params.HttpConnectionManagerParams;

public class HttpTest {
	
	public static void main(String[] args) {
		PoolingHttpConnector conn = new PoolingHttpConnector();
		
		try {
			String response = conn.doGet("http://www.aol.com:80001");
			System.out.println("Response='" + response + "'");
		} catch (IOException e) {
			e.printStackTrace();
		}
	}


	static class PoolingHttpConnector {
		
		public static final int MAX_TOTAL_CONNECTIONS = 16;
		public static final int MAX_CONNECTIONS_PER_HOST = 8;
		public static final int CONNECT_TIMEOUT = 5000;
		public static final int SOCKET_TIMEOUT = 5000;
		public static final boolean TCP_NO_DELAY = true;
		
	    private static MultiThreadedHttpConnectionManager poolManager;
	    private static HttpConnectionManagerParams httpParams;
	    private static HttpClient httpClient;
	    private static boolean initialized = false;
	    
		public PoolingHttpConnector() 
		{
			initialize();
		}

		public String doGet(String url) throws IOException {
			GetMethod method = new GetMethod(url);
					
			try {
	            int status = httpClient.executeMethod(method);	            
		        String response = new String(method.getResponseBody());
	            
	            if (status != HttpStatus.SC_OK)
	            	throw new IOException("HTTP error: " + response);
	            
	            return response;
	            
			} finally {
	            method.releaseConnection();
			}
	 	} 	
	
		private synchronized void initialize() {	
			if (initialized)
				return;
			
	        poolManager = new MultiThreadedHttpConnectionManager();
	        httpParams = new HttpConnectionManagerParams();
	        
	        httpParams.setMaxTotalConnections(MAX_TOTAL_CONNECTIONS);
	        httpParams.setDefaultMaxConnectionsPerHost(MAX_CONNECTIONS_PER_HOST);
	        httpParams.setTcpNoDelay(TCP_NO_DELAY);
	        httpParams.setSoTimeout(SOCKET_TIMEOUT);
	        httpParams.setConnectionTimeout(CONNECT_TIMEOUT);
	        
	        poolManager.setParams(httpParams);
	        httpClient = new HttpClient(poolManager);

			initialized = true;
		}
		
	}
}



","I can reproduce the bug for HttpClient 3.x using the test case. However, the same code ported to 4.0 API seems to work for me without throwing any exception at all. See HttpTest2 attached.

The bug in HttpClient 3.x can be worked around by providing a better implementation of the ProtocolSocketFactory. 

Oleg","HttpClient 3.x is nearing end of life. There is no point fixing it (unless some one volunteers to provide a complete patch in udiff format including test coverage).

Oleg","You said 4.0 doesn't throw exception at all. That's not right behavior either. Since the input is invalid, it should throw a checked exception.

We want to switch to 4.0 but we have a policy not to use software in beta. Do you have an estimate on the official release?

Thanks for your quick response.

Zhihong","> You said 4.0 doesn't throw exception at all. That's not right behavior either. Since the input is invalid, it should throw a checked exception. 

You may be right, but since JRE classes do not raise an exception, I do not think this is HttpClient's job to validate port numbers

> Do you have an estimate on the official release? 

Q2 2009

Oleg","Just tried 4.0. It replaces invalid port with default port in Scheme.resolvePort() without any errors. In my opinion, an exception should be thrown in this case.

","That's certainly wrong. Reopening the issue.

Oleg","Fixed in SVN trunk. Please verify.

Oleg"
HTTPCLIENT-71,RFE,BUG,"Add support for Digest authentication to the Authenticator class",2002-07-16T04:00:12.000+0000,2007-04-22T07:10:02.677+0000,Major,"Here's some code initially whipped up by Geza for Apache Axis, now adapted to
HTTPClient that adds support for Digest authentication to the Authenticator
class. I have tested this code against tomcat 4.0.4 with a sample code that
calls an Apache Axis Web Service. One caveat according to Geza, the code "Right
now does not support qop-int".","Created an attachment (id=2358)
Patch that adds support for Digest authentication
","*** HTTPCLIENT-55 has been marked as a duplicate of this bug. ***","The current patch is good.  The only problem is that it breaks one of the test
cases (a test case that is broken correctly as it trivally tests for the Digest
authentication to fail).

Please provide test cases to TestAuthenticator.java to support this patch.
","Created an attachment (id=2361)
Additional tests for Digest Authentication. (against latest cvs).
","Patches applied.  Closing this bug as the feature has been added with unit
tests.
"
HTTPCLIENT-530,BUG,BUG,"Findbugs reports and fixes",2005-11-24T05:54:14.000+0000,2007-04-22T07:11:11.521+0000,Major,"Ran findbugs 0.94.rc1 on 3.0RC4. 
Fixed a few of the obvious ones (patches to follow) and made notes on the 
remainder - see the //TODO markers in code.
Also created a findbugs target in build.xml - see appropriate patch file","Created an attachment (id=17021)
Patch to add findbugs
","Created an attachment (id=17022)
fb-excludes.xml - Finbugs exclusions
","Created an attachment (id=17023)
fb-csv.xsl - convert fb output to CSV
","Created an attachment (id=17024)
patch showing actual and suggested  fixes
","Sebastian,
We have to concentrate on the most essential stuff for the 3.0 release such as
potential synchronization problems. For instance, I think it is just too late to
start introducing serialVersionUIDs in HttpClient 3.x. Can you also exclude test
and contrib classes from the patch? There's no point in fixing those.

As to the findbugs build target and related classes, would it be a big deal for
you to port those to HttpComponents as well? 

Oleg","Created an attachment (id=17026)
Patch without contrib and test files

Sorry, I thought I had excluded all the test code.
I did not notice that some test code was not in files called Test*.java.

[Using Eclipse, it's very easy to pick and choose which files to include when
applying patches, but I guess other patch applications are not as versatile.]

I'll have a look at extending Findbugs to HttpComponents.","Created an attachment (id=17033)
Patch (take 1)

Here's my take at what should go into the 3.0 release. Please review and let me
know what you think

Oleg","(From update of attachment 17033)
No need to set shutdown as volatile anymore in
IdleConnectionTimeoutThread.java - all the references are now in synchronized
methods.
","Folks, are there any objections to committing the patch, assuming 'shutdown' is
no longer set as volatile? Please review the patch because it is effectively
blocking the 3.0 release.

Oleg","I just spotted something that appeared to be a pretty severe bug in the
IdleConnectionTimeoutThread class. I checked in all the fixes but those to
IdleConnectionTimeoutThread and will file a new bug report shortly

Oleg","Let us revisit this issue in the course of 3.1 development and fix a few other
known issues such as serialVersionUID in serializeable classes

Oleg","serialVersionUID in serializeable classes have been fixed in HttpCore.

Oleg"
HTTPCLIENT-317,RFE,IMPROVEMENT,"HTTP Client doesn't support multipart/related content-type",2004-02-20T21:32:51.000+0000,2008-11-26T12:56:02.135+0000,Minor,"It is not possible to sent data easely as a multipart/related content-type (as 
discribed in rfc 2387) using Http Client.","Just wondering if you have taken a look at the MultipartPostMethod? Currently it
only implements RFC1867, but in most cases that should be sufficient, I believe.

http://jakarta.apache.org/commons/httpclient/apidocs/org/apache/commons/httpclient/methods/MultipartPostMethod.html","Yes of course I had a look to MultipartPostMethod.
I agree that in most cases it is enough to use just MultipartPostMethod class.
That's probably because multipart/related encoding in some way is an extention 
of multipart/form data.
But it is not possible to send data easely that uses features introduced in 
Multipart/Related data

Here are the main problems why it is not possible:

(problem1)- 'multipart related part' in comparison with 'multipart form data 
related part' has additional Content-ID header that 

can be used as the reference from other multipart related parts;
   send(OutputStream out) method of Part class doesn't send Content-ID header;

so HTTP Client will send something like 

--example-2
     Content-Type: Text/x-Okie; charset=iso-8859-1;

     {doc}
     This picture was taken by an automatic camera mounted ...
     {image file=cid:ID-2}
     {para}
     Now this is an enlargement of the area ...
     {image file=cid:ID-3}
     {/doc}

instead of

--example-2
     Content-Type: Text/x-Okie; charset=iso-8859-1;
     Content-ID: ID-1

     {doc}
     This picture was taken by an automatic camera mounted ...
     {image file=cid:ID-2}
     {para}
     Now this is an enlargement of the area ...
     {image file=cid:ID-3}
     {/doc}


(problem2)- addRequestHeaders(HttpState state, HttpConnection conn)  method of 
MultipartPostMethod class
 writes to a "Content-Type" something like : 
"multipart/form-data, boundary=AaB03x" 
and thit is correct for multipart form data(rfc 1867), but for multipart 
related data(according to rfc 2387) this 

method should generate something like:
"multipart/related; boundary=AaB03x; start="ID-1" type="Text/x-Okie"
where  'start' ant 'type' parameters are the content-ID and type of the 
compound object's root body part;

There are another small diferences as well(see rfc 2387).

It looks like the easiest way to make Http Client support multipart/related 
data is to add two classes : e.g. 

MultipartRelatedMethod that extends MultipartPostMethod and implements 
addRequestHeaders(HttpState state, 

HttpConnection conn) method according to rfc 2387 and MultipartRelatedPart 
class that extends Part class and 
implements send(OutputStream out) method according to rfc 2387. Of course 
classes(for all multipart related parts)
should have MultipartRelatedPart as super class.

Could you please comment on this. If you know another way how to overcome this 
problem please tell me. 



","Peter,
I see the point. Unfortunately there's not much we can help you with at the
moment. I personally see implementation of the 'multipart/related' content
handling as being out of scope for HttpClient, as least for a few major releases
to come. Currently there are efforts underway to develop a generic Multipart
Mime library within the Jakarta Commons Codec project:

http://cvs.apache.org/viewcvs.cgi/jakarta-commons-sandbox/codec-multipart/

We certainly plan to integrate the Multipart Mime functionality once it becomes
available as a part of stable commons-codec release. That may take a while,
though. For the time being I am afraid you'll have to handle multipart/related
content encoding manually. 

Oleg
","Oleg,

Thank you for response.
Ok, I'll implement it myself.
It's not that much work.

Peter.

","This followowing two classes I just wrote do the trick for me reg. the 2 problems above... not sure this is fully sufficient? Might help somebody else. Regards, Michael Vorburger.

class MultipartRelatedRequestEntity extends MultipartRequestEntity {

		public MultipartRelatedRequestEntity(Part[] parts, HttpMethodParams params) {
			super(parts, params);
		}

		public String getContentType()
		{
			String header = super.getContentType();
			int ix = header.indexOf( "boundary" );
			String mimeType = "application/soap+xml"; // or "text/xml\", or doesn't actually matter? 
			return "multipart/related; type=\"" + mimeType + "\"; start=\"" + ROOTPART_NAME + "\"; "  + header.substring( ix );
		}
	}

	private static class MultipartRelatedStringPart extends StringPart {

	    protected static final String CONTENT_ID = "Content-ID: <";
	    protected static final byte[] CONTENT_ID_BYTES = EncodingUtil.getAsciiBytes(CONTENT_ID);

	    protected static final String GT = ">";
	    protected static final byte[] GT_BYTES = EncodingUtil.getAsciiBytes(GT);

		public MultipartRelatedStringPart(String name, String value) {
			super(name, value);
		}

		public MultipartRelatedStringPart(String name, String value, String charset) {
			super(name, value, charset);
		}

	    protected void sendDispositionHeader(OutputStream out) throws IOException {
	        out.write(CONTENT_ID_BYTES);
	        out.write(EncodingUtil.getAsciiBytes(getName()));
	        out.write(GT_BYTES);
	    }
	}
","Michael,

> String mimeType = "application/soap+xml"; // or "text/xml\", or doesn't actually matter?
> return "multipart/related; type=\"" + mimeType + "\"; start=\"" + ROOTPART_NAME + "\"; " + header.substring( ix );


AFAIK it makes no sense to specify a type attribute. The MIME type of this part is multipart/related, period. It is a container whose body (beofre the boundary) is usually just empty (or contains a dummy string), and there is no need to specify the type of this emtpyness. 

It is also incorrect to reuse the MIME boundary of the parent. It is a new container and must therefore start with a new boundary string (and close the boundary after the container ends).

","Fixed. See HttpMime

Oleg","It would be fixed in HttpMime, could you please explain how?

Because if I even look into HttpMime 4.1 alpha2 in trunk
there is nothing that generates the Content-ID header in the parts with HttpMultipartMode.STRICT only Content-Type, Content-Disposition and Content-Transfer-Encoding. But Content-ID is NEEDED e.g. in Servicemix as target.
so the above mentioned problem is still open in the latest version but the workaround only would work in 3.1 (legacy)
","OK, I fixed the problem with a new sub-class for FormBodyPart that adds the Content-ID header called SOAPBodyPart
I only would need someone to commit this, as one cannot use MinimalField outside the httpcomponent package, for whatever reason.

---
package org.apache.http.entity.mime;

import org.apache.http.annotation.NotThreadSafe;

import org.apache.http.entity.mime.content.ContentBody;
import org.apache.james.mime4j.descriptor.ContentDescriptor;

/**
 * An extension of the mime4j standard {@link BodyPart} class that 
 * automatically populates the header with standard fields based 
 * on the content description of the enclosed body.
 * 
 *
 * @since 4.0
 */
@NotThreadSafe // Entity is @NotThreadSafe
public class SOAPBodyPart extends FormBodyPart {

    public SOAPBodyPart(final String name, final ContentBody body) {
        super(name, body);

        generateContentID(body);
    }
    
  protected void generateContentID(final ContentDescriptor desc) 
  {
    StringBuilder buf = new StringBuilder();
    buf.append("<").append(getName()).append(">");
    getHeader().addField(new MinimalField("Content-ID", buf.toString()));
  }
}
","MinimalField is a public class. I do not see why this code should be added to HttpMime.

Oleg","Though the MinimalField *class* is public, its *constructor* is still package private.","Fixed in SVN trunk and targeted for inclusion in 4.3.

Oleg"
HTTPCLIENT-852,BUG,BUG,"CircularRedirectException encountered when using a proxy, but not when reaching the target directly",2009-05-28T18:31:52.290+0000,2009-06-01T10:59:19.028+0000,Major,"A CircularRedirectException is encountered when using a proxy (tinyproxy on a remote machine), whereas everything is fine when using no proxy. The target is a URL such as http://www.seoconsultants.com/w3c/status-codes/301.asp which has a 301 redirection.

The issue can be fixed by using ALLOW_CIRCULAR_REDIRECTS set to true (client params), but I can't consider this a "real" fix.

Here is a snippet of code that exemplifies the problem (use your own proxy):

---
String proxyHost = "xyz.webfactional.com";
int proxyPort = 7295;

DefaultHttpClient httpclient = new DefaultHttpClient();
// without a proxy it's OK!
httpclient.getParams().setParameter(ConnRoutePNames.DEFAULT_PROXY,
        new HttpHost(proxyHost, proxyPort, "http"));

HttpParams params = httpclient.getParams();
HttpClientParams.setRedirecting(params, true);
HttpProtocolParams.setUserAgent(params,
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; en-US; rv:1.9.0.10) Gecko/2009042315 Firefox/3.0.10");

// OK, this fixes the problem, but at what cost / other problems ?
//httpclient.getParams().setParameter(ClientPNames.ALLOW_CIRCULAR_REDIRECTS, true);

String url = "http://www.seoconsultants.com/w3c/status-codes/301.asp";

HttpUriRequest request;
HttpResponse response;

request = new HttpGet(url);
System.out.println("request = " + request.getRequestLine());
response = httpclient.execute(request);
System.out.println("status = " + response.getStatusLine());
System.out.println("headers = " + Arrays.asList(response.getAllHeaders()));
---","> I've already opened an issue (HTTPCLIENT-852), sorry if that was inappropriate.

Charles,
That was perfectly appropriate.

> I join with this message 3 logs that show what happens without proxy, with the proxy and with the proxy and the 
> option ALLOW_CIRCULAR_REDIRECTS. 

Could you please attach those logs to this report?

Oleg","Here are the logs. (Didn't see the possibility to attach files at first). I've only edited the logs to hide my real proxy host.","I don't know if it has something to do with the issue, but there's something strange that appears in the log (when using the proxy):

[java] 2009/05/28 19:57:13:507 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: ASPSESSIONIDCSARBQBA][value: JPLPAMKCADCFBCNFOJBFJPMP][domain: www.seoconsultants.com][path: /][expiry: null] match [www.seoconsultants.com:7295/]

7295 is the proxyPort, and shouldn't have anything to do with the target host in the example (www.seoconsultants.com).","I examined the logs and that is what I have found so far: 

The bug in HttpClient is triggered only when the redirect needs to be retried for some reason, for instance, due to an I/O error. There appears to be a bug Tinyproxy's connection management code causing a perfectly re-usable HTTP/1.1 connection to be dropped without proper notification of the client. The proxy should have sent the 'Connection: close' if it was not going to re-use HTTP/1.1connection). HttpClient assumes that the connection is still good, executes the redirect on the same connection, which fails because the connection has been closed on the proxy side. The second retry fails because HttpClient mistakenly assumes the URI has already been visited.

While Tinyproxy's behavior is clearly broken, HttpClient should also be able to deal with failed redirects and retry those correctly. The fix for this issue, however, will require quite a bit of refactoring in the DefaultRequestDirector and DefaultRedirectHandler and may take a few days to complete. 

Oleg","> [java] 2009/05/28 19:57:13:507 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: 
> ASPSESSIONIDCSARBQBA][value: JPLPAMKCADCFBCNFOJBFJPMP][domain: www.seoconsultants.com]
> [path: /][expiry: null] match [www.seoconsultants.com:7295/]

> 7295 is the proxyPort, and shouldn't have anything to do with the target host in the example 
> (www.seoconsultants.com). 

Charles,

Please raise a separate JIRA for this issue.

Oleg","Thanks for your feedback. I appreciate the good work put in this library and will do everything I can to help improve it.","Charles,

I found a bug in the DefaultHttpRequestDirector that caused that issue. Fortunately, the fix was fairly minor in scope. No refactoring was necessary. 

Could you please re-test your application with the latest code snapshot and confirm the issue has been resolved?

You can find compiled snapshots here:

https://repository.apache.org/content/repositories/snapshots/org/apache/httpcomponents/httpclient/4.0-beta3-SNAPSHOT/

Oleg","OK, seems fixed, that's great!"
HTTPCLIENT-667,RFE,IMPROVEMENT,"Provide BestMatch cookie policy",2007-07-14T11:53:17.714+0000,2008-01-21T15:16:43.096+0000,Major,"Presently HttpClient uses a single cookie policy for all target hosts, which is suboptimal for two reasons:
(1) the user needs to know beforehand what kind of HTTP cookie support the target host provides
(2) does not work well with multiple sites with different level of HTTP cookie support 

Introduce new cookie policy that dynamically picks up a CookieSpec (browser compatibility | Netscape draft | RFC2109 | RFC2965) based on properties of the response received from the target host","Implemented in SVN trunk

Oleg"
HTTPCLIENT-501,BUG,BUG,"Minor RFC 2109 / 2965 violation",2005-09-21T04:22:08.000+0000,2007-04-22T07:11:07.790+0000,Minor,"Hi all,

we received this bug report for the debian commons-httpclient
package:

<debian_bugreport>
The following bug is present in upstream, 2.0.2 and 3.0RC3, at least as far
as I can tell by testing.

The specification grammar for the Cookie and Cookie2 HTTP headers
(specified by RFC 2109 section 4.3.4, and RFC 2965 section 3.3.4,
respectively) require that the ordering of pairs is "Version, NAME, path,
domain" (and, in RFC 2965, "port" after "domain"). However, HTTPClient
produces a cookie string with the domain pair appearing before, rather
than after, the path pair. The RFCs specifically *do not* use either the
grammar or the clarifying text ("can occur in any order") that occurs in
the sections that define the Set-Cookie and Set-Cookie2 headers (4.2.2 and
3.2.2, respectively).

Since the sections in question do not, in fact, discuss the issue of pair
ordering in Set-Cookie/Set-Cookie2 at all (other than in using a grammar
that clearly expresses the requirement), and since the complimentary
header explicitly permits them to occur in any order, it seems likely
that HTTPClient is not the only client with this issue, and that most
servers will accomodate this situation (in fact, for it to have gone
unnoticed for this long, it seems likely that either I'm badly misreading
the specification, or no major server has a problem coping with this).
</debian_bugreport>

For your reference the debian bug number:
http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=329245

Regards,

Wolfgang","I fail to see why the order of attributes should matter, but I do not mind
sticking the the strict interpretation of the spec

Oleg","Created an attachment (id=16481)
Test cases

This is a patch for the test cases.","Created an attachment (id=16482)
Proposed fix

This one is easy to fix. Please note that this patch is probably not orthogonal
to the changes on the cookie2 branch and will probably produce a merge
conflict.","Looks good to me. 

As far as I know RFC2109 spec has not changed in the cookie2 branch at all. So,
just patch away. We'll worry about the cookie2 branch later

Oleg","Patch committed.","(In reply to commene. 
> 
> As far as I know RFC2109 spec has not changed in the cookie2 branch at all. So,
> just patch away. We'll worry about the cookie2 branch later
> 
> Oleg

I will make the corresponding changes in the Cookie2 branch soon, although this
seems like a very low priority change to me.

Samit"
HTTPCLIENT-609,IMPROVEMENT,IMPROVEMENT,"Use TRACE logging instead of DEBUG for the absolute nitty-gritties",2006-11-28T14:00:28.000+0000,2007-05-12T11:02:27.014+0000,Minor,"[This is basically a copy of the Spring improvement request SPR-2873: http://opensource.atlassian.com/projects/spring/browse/SPR-2873 )

Given a developer situation: Much of the DEBUG information in the log of HttpClient is very un-interesting as long as it works. Some of these lines are however of much bigger importance than others (thus turning off DEBUG globally for HttpClient isn't good either).

TRACE and DEBUG are the two developer-centric logging levels of log4j and commons logging (the rest are "production levels"). Since log4j-1.2.12, TRACE have existed. Clogging have always had trace, but before release 1.1 mapped Log.trace to log4j's DEBUG, but 1.1 (released May 9. 2006) now maps to log4j's TRACE.

I think that HttpClient's logging would benefit a lot by using TRACE level extensively, in that developers could turn all of httpclient's logging down to DEBUG, but still see "major developer events" like connections being opened, the request being sent, and e.g. the response's status line, size of headers and body, keep-alive vs. closing of connection.

Candidates for TRACE level include:
  * httpclient.wire.*
  * org.apache.commons.httpclient.params.DefaultHttpParams
  * org.apache.commons.httpclient.HttpMethodBase
  * .. and probably a bunch of others that doesn't bring the developer in the standard "good flow mode" any highly interesting information. 

Please note that I do NOT view these lines as worthless. It is however in _normal_ developer circumstances not valuable information, and it would ease development if it was possible to turn these ultra-verbose loglines off easily. When things just aren't working out, and your exciting REST-based query doesn't work out, or your charset encodings just doesn't give what you're expecting, you'd turn on TRACE to really get down to the hard core. You'd find the problem, fix it, and set it to DEBUG again.

In addition, the lines that were left on the DEBUG level should obviously be as informative as possible, and thus maybe somewhat more verbose than now, trying to "aggregate" some pieces of information that now are output over several DEBUG lines..

I do realize that I could achive a lot of this with a rather extensive log configuration, that also had to include raw text filters, but I do believe that this affects more developers than me!

PS: it wouldn't hurt either if all of httpclient's log-lines came from a common root, e.g. "HttpClient", or "org.apache.commons.httpclient", instead of having several roots. This would however be a somewhat "backward incompatible" change, since it now has (at least?) two roots.","Hello Endre,

you are answering most of your suggestions yourself. Let's start with the last one, the different logger roots. That issue is known as HTTPCLIENT-497. Unfortunately, we missed it for 3.0 as well as 3.1 and can't change it now in 3.x without breaking compatibility. That's a clear wontfix.

For the rest, we have only two developer log levels to choose from, and we must use them carefully. For example, the wire log which you mention uses DEBUG for the status/response and header lines and TRACE for the message entities. That's because we want to be able to get a wire log of the headers without potentially dumping megabytes of binary data we're not interested in. Other parts of HttpClient may face similar tradeoffs.
The developer log levels are there so we, the developers, can get information we require to help users when debugging problems in various places throughout the HttpClient code. I think it is not undue that we are allowed to use two different developer log levels everywhere in order to reduce the logging noise where appropriate. If you decide to switch on DEBUG traces for _all_ of HttpClient, it's only fair that you suffer the consequences. I don't think we should have to restrain ourselves to all-or-nothing logging for DefaultHttpParams or HttpMethodBase or any other part of HttpClient because you're only interested in some of the log messages and don't want to bother with configuring your logging framework accordingly.

Saying that, if you feel there are parts of the code where we _locally_ used the two developer log levels inappropriately, or where log message phrasing could be improved, we'll happily review, discuss, and accept patches :-) I'm afraid we don't have the personpower available to perform a review of log levels for the old code base just for the fun of it. HttpClient 3.x is on life support because we are focusing our efforts on HttpComponents 4.0.

cheers,
  Roland
","@Roland: I don't quite see what you're answering/commenting - did you read the entire description?!

I did NOT at ANY POINT say that you should stop using DEBUG: I've however not seen a single log-line from httpclient that outputs on TRACE. (Full wire-dump doesn't belong in DEBUG, IM(F)O)

In my description, I try to point out that I'd appreciate IF you DID use TRACE "somewhat more extensively" (given that it isn't used at all now, AFAICS).

And I came up with some quick candidates for which loglines that would be better sent to TRACE than DEBUG.

Given that I do not suggest that you delete one single log-statement, only "downgrade" some loglines from DEBUG to TRACE, I do not understand where you're coming from in your comment at all.

Also, I firmly believe that you folks should think of "the developers" not as yourself, but as the users of your library. There are many more of the latter than the former. However, given, again, that I do not suggest that you delete one single logline, I can't seem to get why not both camps could be pleased in this particular situation.","Endre,

It would help a lot if you attached to this issue a diff -u with your suggested trace logs.  It should generally not be a problem for us to move some of the log down to TRACE level. Personally I favour the finer level granularity especially in large systems that use lots of components (see JBoss for instance). It allows to dig deep into the inner workings if necessary but keeps log down normally.

Ortwin","Hello Endre,

yes, I read your entire description at least twice before answering. It does not mention anywhere that TRACE level is not used at all. If that is indeed the case (I haven't checked) I agree that this could be improved by making use of both log levels. Remember my invitation to provide patches?
Your examples include wire logging, which is exactly the place where I know we've been using both levels. The other specific examples are not DEBUG statements that should be downgraded, but whole classes - which I interpreted as a request to downgrade all DEBUG statements in those classes. Just moving all log/trace statements of a whole class from DEBUG to TRACE is imho not an improvement. If all output is currently at DEBUG level, it's not a deterioration either, I'll grant you that. It's just work that somebody has to do.
What you actually suggest is that we review all DEBUG level log statements and decide which of them should be downgraded. That is a _lot_ of work, and we already have more work on our list than can be achieved in a reasonable amount of time by those active developers we have. Remember my invitation to provide patches? Reviewing patches is work as well, but it's something I am willing to spend time on.

I have adopted the terminology which is commonly used on our mailing lists and in our wiki. Developers are folks working on our code base, users are folks using our code base. We put a lot of effort into keeping our users happy and satisfied. Logging is one of the tools we require to do that. But it's not a core functionality that is broken and needs fixing. It could be improved all right. The question is: who's going to spend the time for doing that?
Since you're probably not familiar with our staffing situation, here is a short overview. We have one and a half active developers. Since about a year ago, we are putting our efforts into a _complete_ overhaul of the API and code base, to become HttpComponents 4.0. We've made some progress, but we're still months if not years away from even a beta of HttpClient 4.0. There is a reason why we overhaul the API completely: the 3.x API is broken by design. We've put in as much functionality as can reasonably be put in (maybe even more), but we can't continue along that road. The code needs a complete rework, and that's what we're doing. Which means that 3.x is a legacy code base into which we'll put as much effort as needed, but as little effort as possible.
We are all quite willing to keep both camps happy. To keep "our" camp happy, all you have to do is find someone who's going to submit patches. Both Oleg and I, and probably also some of the less active committers, will gladly spend our time on reviewing such patches so they can be integrated into the code base. And we'll do that out of respect for the effort of whoever it is that comes up with the patches. What you can not expect Oleg or me to do is to spend our limited time on cosmetic improvements of the legacy code base, while the todo list for the new code base is growing from months to years. If something is broken in 3.x, we'll fix it. If somebody submits patches for improvements, we'll review them to get them in as quickly as possible. But we're not going to do code reviews for mere improvements.

I hope this clarifies things a bit. My response was not meant to imply your suggestions are unreasonable. I rather wanted to point out that they are cosmetic in nature, have a minimal priority on our list, and there's nobody at hand to do the work. If anyone steps forward to help maintain the legacy code base, we'll gladly support such effort.

cheers,
  Roland
","Yes it clarifyes things a good bit. I guess I didn't realize the extent to which 3.x is "abandoned". Looking forward to a new'n'fresh 4.0, then! :)  (with new'n'fresh bugs?! :) )

I guess simply coming up with an "exact" set of log-lines that could do with trace doesn't cut it? It has to be actual patches? (Setting up a new project just takes some time..)

If you'd just set the one log-line that dump the wire (Onto logger "httpclient.wire.content") to do log.trace(..) instead of log.debug(..) next time you're around that code, that would help a lot, I believe.
  (Actually, the number of bytes read in one chunck could be nice to have output on debug, in addition to all the actual wire content ouput on trace - this would give a nice interleaving effect with the processing of the body of the response, so that _my_ debug or trace lines was interleaved with the actual TCP connection "chunk" fetching..).

I'll try to come up with a patch for some more.

NB/PS: Once again, I actually think that _extensive_ logging og httpclient rocks. Having the actual wire-content available in such a nice output is really nice. It's just "a bit" on the verbose side when things actually are working!

Thanks,
Endre.","Abandoned may be too strong a word. The point is further improvement of HttpClient is simply not feasible without fundamental changes in the core components (see [1]). HttpClient 3.x line will be supported until HttpClient 4.x is ready and well tested. This said, anyone how wants new features / non-critical fixes in HttpClient 3.x must be prepared to 'scratch his/her own itch'

Oleg

[1] http://jakarta.apache.org/httpcomponents/commons-httpclient-lessons.html","No more annoying and completely useless TRACEs. HttpClient now produces much more conciser logs 

Oleg"
HTTPCLIENT-926,RFE,RFE,"Add Amazon S3 authentication support",2010-03-14T05:31:43.169+0000,2010-04-14T20:00:38.898+0000,Major,"Add support for the the Amazon S3 authentication scheme as defined by the online document: http://docs.amazonwebservices.com/AmazonS3/latest/index.html?RESTAuthentication.html","Implementation of Amazon's spec. Verified working against HttpClient 4.0 and 4.1.alpha1.","Jean-Philippe

I committed the code you contributed to the SVN repository. I made some minor changes to the exception handling code and also had to remove @author tags. Please review.

http://svn.apache.org/viewvc?rev=934160&view=rev

Many thanks for this contribution

Oleg","Hi Jean-Philippe

I was testing this and noticed that the Base64.encodeBase64String() inserts a CRLF even when the size is much less than 76 characters.. and thus causes problems (a connection reset from Amazon for a GET request in my test)

// base64-encode the hmac
result = Base64.encodeBase64String(rawHmac);

A simple replace as follows fixes this issue, but as I am not much familiar with the AWS/S3 API want to check this with you if this indeed is a simple oversight or if there could be other cases I am not aware of

// base64-encode the hmac
return Base64.encodeBase64URLSafeString(rawHmac);

cheers
asankha
","Seems like my earlier comment was written in a hurry.. I still have issues and will get back with my findings :)","My earlier suggestion has been reporting a successful response, but with an error that the signature did not match which I did not notice .. 

A working solution is to just remove the trailing \r\n which otherwise can be interpreted as part of another [malformed] request. Since this is only at the end, this should not cause an issue - but if a \r\n indeed does occur within the header value due to some long signature etc, that could still cause problems..

For now, I've checked this into SVN

String headerValue = NAME + " " + credentials.getUserPrincipal().getName() + ":" + signature.trim();

cheers
asankha","Hi Asankha

Thanks for the feedback. I've found a similar issues with the code that I had to use some workarounds for. I'm continuing to investigate this and will take your considerations into account. I also discovered an issue with some S3 based servers required the Content-MD5 header to be set. I will be submitting an update to the code that hopefully addresses your issue plus the Content-MD5 issue.

Cheers,
Jean-Philippe"
HTTPCLIENT-46,RFE,IMPROVEMENT,"Plug-in authentication modules",2002-07-15T09:21:01.000+0000,2006-05-15T21:44:49.000+0000,Minor,"Currently only basic authentication is supported.  A Authentication interface
should be provided to allow for plug-in support for other authenticaiton
schemes, some of which may be application specific and therefore have no place
in httpclient itself, but would be required by some users.","Plug-in mechanism for authentication schemes has been implemented in CVS HEAD"
HTTPCLIENT-1027,DOCUMENTATION,IMPROVEMENT,"Some typos in the English Manual",2010-12-01T13:00:32.221+0000,2010-12-01T15:41:02.590+0000,Major,"in section 2.8.4
Per default this implementation will create no more than than 2 concurrent connections per given route and no more 20 connections in total.
Here are 2 "than" in this statement.

in section 3.1
Netscape engineers used to refer to it as as a "magic cookie" and the name stuck.
Also, here are 2 "as" in the sentence.

in section 5.2 'http.protocol.handle-redirects'
If this parameter is not HttpClient will handle redirects automatically.
here, a "set" should be put after not

in section 6.1
In certain situations it may be necessary to customize the way HTTP messages get transmitted across
the wire beyond what is possible possible using HTTP parameters in order to be able to deal nonstandard,
non-compliant behaviours.
here are 2 "possible".","Thanks! Fixed in SVN, will be in the next release."
HTTPCLIENT-965,BUG,BUG,"cache does not honor must-revalidate or proxy-revalidate Cache-Control directives",2010-07-02T16:59:26.893+0000,2010-07-07T16:11:24.982+0000,Major,"http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4

There are a couple of missed requirements here regarding must-revalidate and proxy-revalidate (which applies only to shared caches).
1. When a cache entry with this directive is revalidated, it must be an end-to-end revalidation (meaning it must include 'max-age=0' on the request).
2. If the revalidation with the origin fails, the cache MUST NOT return a stale entry and MUST return a 504 response.
","The provided patch fixes this issue by adding 'max-age=0' to revalidations for these directives and generating a 504 if there is an IOException when attempting to revalidate a stale entry.

There is a related issue:
https://issues.apache.org/jira/browse/HTTPCLIENT-962

where it is not currently clear if the cache is a shared cache or not. The conservative assumption here is that we are a
shared cache, and hence must-revalidate and proxy-revalidate are essentially the same.

However, the unit tests for proxy-revalidate in TestProtocolRequirements are conditional on whether the CachingHttpClient claims to be a shared cache or not.

This patch is contributed to the ASF with the permission of my employer.
","Patch checked in. Many thanks, Jon

Oleg"
HTTPCLIENT-404,BUG,BUG,"SO_TIMEOUT parameter on the method level has no effect",2004-12-17T05:48:51.000+0000,2007-04-22T07:10:54.625+0000,Major,"This bug has been reported on the HttpClient user list by Ilya Kharmatsky <ilyak
-at- mainsoft.com>","Created an attachment (id=13767)
Patch

If I hear no complaints I'll commit the patch in a day or so","Patch committed.

Oleg"
HTTPCLIENT-384,IMPROVEMENT,BUG,"3.0 not compile-time compatible with 2.0 library usage",2004-09-30T07:11:48.000+0000,2007-04-22T07:10:52.473+0000,Major,"To my surprise Oleg says this was the intent, yet the Jakarta-Slide webdavclient
libraries do not compile out of the box.  Patch for that issue to follow.","Created an attachment (id=12900)
Restores compatibility with 2.0 clients.
","I felt it appropriate to change the methods in URIException as well to
correspond to the fact that it was now overriding methods from HttpException
again.  Not sure that this was exactly the correct thing to do.","> To my surprise Oleg says this was the intent

You know I am evil ;) I'd choose any day to break an API instead of making ugly
hack around, but Mike keeps me in check.

Changes to URIException look just fine to me.

I'll apply the patch tonight (20:00 GMT) provided there are no objections.

Oleg  ","Patch committed

Oleg"
HTTPCLIENT-972,RFE,IMPROVEMENT,"caching module should use HttpParams-style configuration",2010-07-28T13:47:49.853+0000,2010-07-29T08:35:08.885+0000,Minor,"The constructor for CachingHttpClient currently accepts combinations of:
* HttpCache
* HttpClient
* integer for max object size in bytes

As I started looking at being able to configure this for behaving as a non-shared cache, I realized that we actually want to be replacing that last int with an HttpParams argument, and tracking all the various options in that style. I have a patch with this update which I will upload shortly.
","The attached patch addresses this issue by creating an org.apache.http.client.cache.params package and moving configuration parameters into that (I used the AuthParams as a template for this).

One note is that this patch breaks backwards-compatibility, but I think this puts us in a good spot going forward with being able to extend HttpParams as needed, and if we are going to do this, we ought to do it before GA.

This patch is contributed to the ASF with the permission of my employer.
","Jon

HttpParams API often get criticized these days as being cumbersome and user unfriendly because it is difficult to manipulate with using DI frameworks. While there is currently no replacement for HttpParams when it comes to managing HTTP parameters that need to be settable on both per agent and per request basis, I am certainly guilty for having abused HttpParams in areas where simple plain java beans would have sufficed (mainly in HttpCore NIO). Since caching configuration does not seem to make sense at the HTTP request level, probably we should use plain beans for cache configuration? What do you think?

Oleg","I'm fine with a simple beans-style configuration for the Cache; I just tried to copy what was already in other parts of the codebase. :) 

I'm assuming something like a CacheParams class that starts with default settings, plus getters and setters, and then passing those as the constructor args where needed instead of HttpParams?

I can take a shot at a patch for that.
","Attaching a patch that does cache configuration with a simple beans-style CacheParams object.

This patch is contributed to the ASF with the permission of my employer.","Patch checked in with some minor tweaks.

Oleg"
HTTPCLIENT-1026,TASK,BUG,"Properly close resources",2010-11-30T20:18:37.406+0000,2011-01-05T20:40:17.709+0000,Major,"Java has exceptions so resources must always be closed on a finally clause","You may want first to commit a patch to remove whitespace at the end of the line and then apply this patch.","Eduardo

If you want this patch applied you should also change other examples to make them consistent.

Oleg","I missed httpmime example.
Any other example?
","My bad. I did not look at the patch carefully enough. All examples seem there. I will review and apply the patch in the coming days.

Oleg","Eduardo

Patches do not apply cleanly against the latest SVN trunk. Could you please create a new diff against the latest snapshot off the SVN trunk?

Oleg","Patch against trunk","Patch checked in. Many thanks, Eduardo

Oleg"
HTTPCLIENT-165,BUG,BUG,"'100-continue' response times out unexpectedly",2003-02-26T22:25:39.000+0000,2007-04-22T07:10:15.969+0000,Major,"Entity encosing methods time out (3 seconds) rather than getting the
100-continue response. Then, after it has send the body, the 100-continue
response is received and returned.

Adding

  method.setUseExpectHeader(false);

seems to fix it.

Platform 1: Jetty server on Windows XP, Sun JDK 1.4.1_01, 
Platform 2: Tomcat-4.1.18 + Turbine on Windows 2000 Pro, Sun JDK 1.3.1
Platform 3: Tomcat-4.1.18 on Linux if the connection is running over stunnel-4.00

Reported by: 
 Simon Roberts <simon.roberts@fifthweb.net>
 Aurelien Pernoud <apernoud@sopragroup.com>
 Ingo Brunberg <ib@fiz-chemie.de>","Guys,
Could you please install test webapp and run standard HttpClient test cases on
your system?

Please refer to the document below for instructions

http://jakarta.apache.org/commons/httpclient/testwebapp.html

I need to know if the problem can be reliably reproduced or it occurs only
sporadically.

Oleg","Created an attachment (id=5057)
Output from test-local of testwebapp, installed into Jetty server
","Previous attachment is the system described as "Platform 1".

NOTE: the issue actually happens using HTTPS, and I'm unable to test with HTTP 
(the certificate is critical for my application).","I have also encountered this same bug using httpclient to access an https server
using client side certificates.","Created an attachment (id=5119)
RFC 2616 (chapter 10.1) compliance fix
","The patch does not really fix address the cause of the problem. I merely fixes 
RFC2616 non-compliant handling of 100 responses, which should prevent 
HttpClient from failing when an unexpected 100 (continue) response is received

RFC2616:

"10.1 Informational 1xx

   ...

   A client MUST be prepared to accept one or more 1xx status responses
   prior to a regular response, even if the client does not expect a 100
   (Continue) status message. Unexpected 1xx status responses MAY be
   ignored by a user agent.

   ..."

Vagueness of this particular paragraph begs a question. Shouldn't HttpClient 
ignore the complete 1xx range in order to be 100% compliant? As far as I know 
protocol change response (status code 101) is not currently supported

Oleg
","I agree, it seems like all 1XX responses should be ignored.  Other than support
for ignoring other 1XX responses I would say this patch is good to go.

Mike","Created an attachment (id=5124)
RFC 2616 (chapter 10.1) compliance fix (take 2)
","Looks good to me.  Nice work Oleg.  This makes the code for handling
100-continue much cleaner.","Created an attachment (id=5148)
RFC 2616 (chapter 10.1) compliance fix (take 3)
","New patch removes CPU-bound busy wait used when expecting a 100 response. 
Socket SO_TIMEOUT is used instread.

Suggested by Simon Roberts","Patch has been committed. Please retest and inform me if the problem still persists

Oleg","*** HTTPCLIENT-179 has been marked as a duplicate of this bug. ***"
HTTPCLIENT-440,BUG,BUG,"Exception in HttpConnection because of unchecked buffer size",2005-03-10T18:19:11.000+0000,2007-04-22T07:10:58.986+0000,Major,"From the httpclient-dev mailing list:

Date: Tue, 8 Mar 2005 19:08:35 +0100
Subject: Error with multiple connections

Hello,

 

I am having some problems while trying multiple connections over a
HttpClient object with a MultiThreadedHttpConnectionManager. I am
launching 10 threads and each thread executes some GetMethods using this
HttpClient object.

 

Some times I got an error like this:

 

java.lang.IllegalArgumentException: Buffer size <= 0

      at java.io.BufferedInputStream.<init>(Unknown Source)

      at
org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:70
3)

      at
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpCon
nectionAdapter.open(MultiThreadedHttpConnectionManager.java:1170)

      at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:6
28)

      at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:4
97)

      at Main$Hilo.run(Main.java:58)

 

Does anybody have any idea? 

 

Thanks in advance,

Jorge","Created an attachment (id=14451)
Proposed fix

API Docs of socket.getReceiveBufferSize() and socket.getSendBufferSize() do not
state if the return value can be negative or not. The fix allocates 2KB of
buffers if the returned size is <=0.","The same code is present in the 3.0 code base. Any fix should be ported.","Looks good to me.

Oleg"
HTTPCLIENT-510,RFE,IMPROVEMENT,"User-defined ProtocolSocketFactory for secure connection through proxy",2005-10-18T03:59:27.000+0000,2007-04-22T07:11:08.872+0000,Minor,"I use a custom socket implementation with HttpClient, and am having problems 
getting secure connections through a proxy working.

HttpClient requires that my SecureProtocolSocketFactory be able to create a 
secure socket layered over an existing insecure socket, but does not specify 
how that insecure socket is created. Currently, for secure proxied 
connections, the insecure connection is always created using a 
DefaultProtocolSocketFactory (HttpConnection.java, line 702). I wish to be 
able to override this behaviour, so that I can create the insecure socket 
using my own custom implementation.

The problem with the default behaviour is that my custom socket implementation 
is written in C++ using JNI, and the SSL implementation is handled at the 
native level. Hence, layering over an existing JDK socket will not work.

My proposed solution is to add an HTTP connection parameter to specify the 
socket factory to use, perhaps http.connection.insecuresocketfactory of type 
Class.","Created an attachment (id=16724)
Patch (take 1)

This is what we can do for the 3.0 release. Please let me know if that
suffices. 

We can consider adding a new parameter for the 3.1 release if the proposed fix
is not sufficient.

Oleg","That fix will be perfectly sufficient.","Folks,
Please review the patch and let me know if it is okay to check it in

Oleg","I think you can also remove the
import org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory;
at the top of the file.

Many thanks for the quick response on this issue.
","The patch looks good.","Looks good. We should add a note on the behaviour to the SSL-Guide.","Patch checked in

Oleg"
HTTPCLIENT-985,BUG,BUG,"cache module should populate Via header to capture upstream and downstream protocols",2010-09-02T14:38:54.135+0000,2010-09-02T21:08:41.228+0000,Major,"Because the cache module is currently implemented as a decorator that behaves like a transparent caching proxy, we need it to correctly populate the Via header so that we can preserve the record of which protocol versions were used upstream and downstream from the caching module.

This is a MUST per the RFC:
http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.45","I've uploaded a patch that fixes this issue, including unit tests. One area for discussion is how to populate the comment section of the Via header (if we want to include one). Currently the implementation follows the format of the User-Agent set by DefaultHttpClient, so:

Via: 1.1 localhost (Apache-HttpClient/4.1-alpha3-SNAPSHOT (cache))

This patch is contributed with the permission of my employer.","Patch checked in. Many thanks, Jon

Oleg"
HTTPCLIENT-1034,DOCUMENTATION,IMPROVEMENT,"Add link to "Benchmarking the HttpClient Caching Module" article from Comcast Interactive Media",2010-12-13T15:53:35.526+0000,2011-01-21T20:05:00.786+0000,Minor,"I'd like to add a link into the HttpClient docs detailing some benchmarking we did with the HttpClient Cache module.","This patch includes 2 modifications:
1) Adds link to "HttpClient Cache" module in left "module" list
2) Adds link to benchmarking doc in HttpClient Cache docs under "External Documentation"","Patch is committed to trunk; still waiting on getting it published to the live dev site.
","Assigning to Oleg for the final publish to the live website, since he offered. :)","Done.

http://hc.apache.org/httpcomponents-client-ga/httpclient-cache/index.html

Oleg"
HTTPCLIENT-163,BUG,BUG,"HttpClient does not compile 'out of the box' in IBM's VisualAge IDE",2003-02-18T23:30:49.000+0000,2007-04-22T07:10:15.654+0000,Major,"This was observed with IBM VisualAge 3.5, which runs JDK1.2.2:

Importing the HTTPClient source code into the IDE brings up a
compilation error in 

org.apache.commons.httpclient.HttpMethodBase.

The initialization of "private ResponseConsumedWatcher m_responseWatcher"
using an anyonymous inner class seems to cause some trouble. Implicated code:

private ResponseConsumedWatcher m_responseWatcher = new ResponseConsumedWatcher
() {
	public void responseConsumed() {
		responseBodyConsumed();
	}
};

The error message is: "Field initialization: The constructor invoked to create
org.apache.commons.httpclient.HttpMethodBase$1 with arguments () is not defined"

...but only in the context of HttpMethodBase(String uri) constructor, i.e.
the HttpMethodBase() constructor *can* be compiled, HttpMethodBase(String uri)
*cannot* be compiled with error "Cannot create constructor due to incorrect
field initialization".

I interpret this to mean that the compiler is looking for a parameterless
constructor for the anonymous class in the context of 
HttpMethodBase(String uri). The message did not really make sense to me. 
Checked the syntax, checked in the Language Definition whether setting up an
anonymous class like that is permitted; found nothing obviously wrong.

Fix:

The code above is equivalent to constructing the instance at the beginning
of each constructor of the enclosing class. A copy and paste of the
construction code into each of the two constructors fixes things...until
the next update.","IBM's compiler is known to be a bit picky about the syntax sometimes (which
personally I find okay). Strange though, that Eclipse does not have problems.
Easy to fix and important to make the sources compatible to common compilers. So
scheduling this for beta.","David,
You will need to provide your own patch for this.  The current cvs HEAD builds
fine with jdk1.2.2 (still 3 tests failing) and j2sdk1.4.1.  I don't have
VisualAge, only Eclipse and Sun runtimes so can't test any patch either but will
take your word for it as long as jdk1.2.2 and j2sdk1.4.1 are still OK.
","Created an attachment (id=5079)
fix
","Attached is a patch that fixes this particular case.  There may be other places
in the code base that will not compile in VisualAge.  I tried to get IBM's 1.2.2
JDK but it seems that it is no longer available.  Only 1.3 is on their site now
and it does not seem to be as picky.  Just to note, Visual Age is nearly at its
end of life.  IBM will no longer be supporting it after the end of the year. 
They are recommending that people upgrade to WebSphere Application Developer,
which is just Eclipse plus some extras like hooks into WebSphere.

Mike"
HTTPCLIENT-574,DESIGN_DEFECT,BUG,"Subclasses do not have write access to StatusLine",2006-04-02T20:54:47.000+0000,2006-08-07T10:50:15.000+0000,Major,"HttpMethodBase provides the readStatusLine method explicitly designed for
subclasses to override. However, any attempt to do so quickly encounters issues
since the subclass does not have access to the statusLine member variable in
HttpMethodBase. The same holds true for several other member variables as well.

Recommend that all access to member variables occur through accessors and that
mutators be provided to set them. See patch below.
----------------------------------------------------------

Index: HttpMethodBase.java
===================================================================
--- HttpMethodBase.java	(revision 390815)
+++ HttpMethodBase.java	(working copy)
@@ -563,7 +563,7 @@
      * @return the status code associated with the latest response.
      */
     public int getStatusCode() {
-        return statusLine.getStatusCode();
+        return getStatusLine().getStatusCode();
     }
 
     /**
@@ -577,6 +577,13 @@
     }
 
     /**
+     * @param statusLine The statusLine to set.
+     */
+    protected final void setStatusLine(StatusLine statusLine) {
+        this.statusLine = statusLine;
+    }
+
+    /**
      * Checks if response data is available.
      * @return <tt>true</tt> if response data is available, <tt>false</tt>
otherwise.
      */
@@ -798,7 +805,7 @@
      * @return The status text.
      */
     public String getStatusText() {
-        return statusLine.getReasonPhrase();
+        return getStatusLine().getReasonPhrase();
     }
 
     /**
@@ -920,16 +927,16 @@
         }
         LOG.debug("Resorting to protocol version default close connection policy");
         // missing or invalid connection header, do the default
-        if (this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {
+        if (getEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {
             if (LOG.isDebugEnabled()) {
-                LOG.debug("Should NOT close connection, using " +
this.effectiveVersion.toString());
+                LOG.debug("Should NOT close connection, using " +
getEffectiveVersion().toString());
             }
         } else {
             if (LOG.isDebugEnabled()) {
-                LOG.debug("Should close connection, using " +
this.effectiveVersion.toString());
+                LOG.debug("Should close connection, using " +
getEffectiveVersion().toString());
             }
         }
-        return this.effectiveVersion.lessEquals(HttpVersion.HTTP_1_0);
+        return getEffectiveVersion().lessEquals(HttpVersion.HTTP_1_0);
     }
     
     /**
@@ -980,14 +987,14 @@
         this.responseConnection = conn;
 
         checkExecuteConditions(state, conn);
-        this.statusLine = null;
+        setStatusLine(null);
         this.connectionCloseForced = false;
 
         conn.setLastResponseInputStream(null);
 
         // determine the effective protocol version
-        if (this.effectiveVersion == null) {
-            this.effectiveVersion = this.params.getVersion(); 
+        if (getEffectiveVersion() == null) {
+            setEffectiveVersion(this.params.getVersion()); 
         }
 
         writeRequest(state, conn);
@@ -996,7 +1003,7 @@
         // the method has successfully executed
         used = true; 
 
-        return statusLine.getStatusCode();
+        return getStatusCode();
     }
 
     /**
@@ -1048,8 +1055,8 @@
         getRequestHeaderGroup().clear();
         getResponseHeaderGroup().clear();
         getResponseTrailerHeaderGroup().clear();
-        statusLine = null;
-        effectiveVersion = null;
+        setStatusLine(null);
+        setEffectiveVersion(null);
         aborted = false;
         used = false;
         params = new HttpMethodParams();
@@ -1586,18 +1593,18 @@
         "enter HttpMethodBase.readResponse(HttpState, HttpConnection)");
         // Status line & line may have already been received
         // if 'expect - continue' handshake has been used
-        while (this.statusLine == null) {
+        while (getStatusLine() == null) {
             readStatusLine(state, conn);
             processStatusLine(state, conn);
             readResponseHeaders(state, conn);
             processResponseHeaders(state, conn);
             
-            int status = this.statusLine.getStatusCode();
+            int status = getStatusCode(); 
             if ((status >= 100) && (status < 200)) {
                 if (LOG.isInfoEnabled()) {
-                    LOG.info("Discarding unexpected response: " +
this.statusLine.toString()); 
+                    LOG.info("Discarding unexpected response: " +
getStatusLine().toString()); 
                 }
-                this.statusLine = null;
+                setStatusLine(null);
             }
         }
         readResponseBody(state, conn);
@@ -1675,7 +1682,7 @@
         if (Wire.CONTENT_WIRE.enabled()) {
             is = new WireLogInputStream(is, Wire.CONTENT_WIRE);
         }
-        boolean canHaveBody = canResponseHaveBody(statusLine.getStatusCode());
+        boolean canHaveBody = canResponseHaveBody(getStatusCode());
         InputStream result = null;
         Header transferEncodingHeader =
responseHeaders.getFirstHeader("Transfer-Encoding");
         // We use Transfer-Encoding if present and ignore Content-Length.
@@ -1714,7 +1721,7 @@
         } else {
             long expectedLength = getResponseContentLength();
             if (expectedLength == -1) {
-                if (canHaveBody &&
this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {
+                if (canHaveBody &&
getEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {
                     Header connectionHeader =
responseHeaders.getFirstHeader("Connection");
                     String connectionDirective = null;
                     if (connectionHeader != null) {
@@ -1850,19 +1857,19 @@
         } while(true);
 
         //create the status line from the status string
-        statusLine = new StatusLine(s);
+        setStatusLine(new StatusLine(s));
 
         //check for a valid HTTP-Version
-        String versionStr = statusLine.getHttpVersion();
+        String versionStr = getStatusLine().getHttpVersion();
         if (getParams().isParameterFalse(HttpMethodParams.UNAMBIGUOUS_STATUS_LINE) 
            && versionStr.equals("HTTP")) {
             getParams().setVersion(HttpVersion.HTTP_1_0);
             if (LOG.isWarnEnabled()) {
                 LOG.warn("Ambiguous status line (HTTP protocol version missing):" +
-                statusLine.toString());
+                getStatusLine().toString());
             }
         } else {
-            this.effectiveVersion = HttpVersion.parse(versionStr);
+            setEffectiveVersion(HttpVersion.parse(versionStr));
         }
 
     }
@@ -1943,9 +1950,9 @@
                     readResponseHeaders(state, conn);
                     processResponseHeaders(state, conn);
 
-                    if (this.statusLine.getStatusCode() ==
HttpStatus.SC_CONTINUE) {
+                    if (getStatusCode() == HttpStatus.SC_CONTINUE) {
                         // Discard status line
-                        this.statusLine = null;
+                        setStatusLine(null);
                         LOG.debug("OK to continue received");
                     } else {
                         return;
@@ -2087,7 +2094,7 @@
      */
     private String getRequestLine(HttpConnection conn) {
         return  HttpMethodBase.generateRequestLine(conn, getName(),
-                getPath(), getQueryString(), this.effectiveVersion.toString());
+                getPath(), getQueryString(), getEffectiveVersion().toString());
     }
 
     /**
@@ -2128,6 +2135,13 @@
     }
 
     /**
+     * @param effectiveVersion The effectiveVersion to set.
+     */
+    protected final void setEffectiveVersion(HttpVersion effectiveVersion) {
+        this.effectiveVersion = effectiveVersion;
+    }
+
+    /**
      * Per RFC 2616 section 4.3, some response can never contain a message
      * body.
      *
@@ -2358,7 +2372,7 @@
     ) {
         // set used so that the response can be read
         this.used = true;
-        this.statusLine = statusline;
+        setStatusLine(statusline);
         this.responseHeaders = responseheaders;
         this.responseBody = null;
         this.responseStream = responseStream;","Created an attachment (id=18014)
Patch
","(In reply to comment #0)
> HttpMethodBase provides the readStatusLine method explicitly designed for
> subclasses to override. However, any attempt to do so quickly encounters issues
> since the subclass does not have access to the statusLine member variable in
> HttpMethodBase. The same holds true for several other member variables as well.
> 
> Recommend that all access to member variables occur through accessors and that
> mutators be provided to set them. See patch below.

This _may_ be right. However I personally would very much rather keep things as
they are at the very least for the sake of consistency, unless the same coding
convention can be applied throughout the entire code base. Moreover,
HttpMethodBase class will go as version 4.0. There's no point in trying to apply
a new coding convention to something which is fundamentally flawed conceptually.

Could you please come up with a patch that just provides access to private
instance variables that you need with the minimal impact on the existing code?

Oleg","The only other option, which is lass safe, is to change all private member
variables to protected. If this is what you prefer I can produce a patch for it.","(In reply to comment #3)
> The only other option, which is lass safe, is to change all private member
> variables to protected. If this is what you prefer I can produce a patch for it.

What about just a protected getter?

Oleg","The getter is already public for statusLine. The attached patch has a protected
setter and changes the rest of the code to use both the getter and setter
instead of using the member variable directly. For example,
"setStatusLine(null);" is used instead of "statusLine = null;" Same thing for
effectiveVersion.

I am no longer sure I understand what you meant by keeping a consistent coding
style. Could you elaborate?","I thought the whole issue was one could not have access to some private instance
variable because they did not have a corresponding protected getter. If that is
the case I am fully prepared to accept a patch for it. Otherwise I see no point
in providing protected setters for a _limited_ number of private instance
variables in a _single_ class just because some believe this is a better way.

It is just not feasible that we patch HttpMethodBase in order to please every
single user out there. HttpMethodBase is helplessly broken. It simply needs to go.

I hope this makes my position clearer

Oleg","If I have offended you then I appologize. I did not open this issue just because
I think it could be done a better way. I have not commented on the suitability
of the code. I would like to try again :-)

readResponse enters a loop looking for a non-null statusLine. readStatusLine is
responsible for setting the variable to a non-null value. If I override
readStatusLine I cannot set the variable and readResponse is stuck in the loop.
I cannot override getStatusLine since readResponse uses the variable directly.

I see four solutions here. Never override readStatusLine (should be private),
make variable protected, add a setter, or change code to use existing getter.
Any of the last three will work for me.

The same problems exist with the other member variables; I just used statusLine
as an example. I can resubmit the patch for any solution you choose and I can
ensure that all member variables are accessed in a consistent manner.","(In reply to comment #7)
> If I have offended you then I appologize. I did not open this issue just because
> I think it could be done a better way. I have not commented on the suitability
> of the code. I would like to try again :-)
> 

No offense taken at all. The point I was trying to make (rather unsuccessfully)
is that merits of what some may consider a good practice tend to be subjective
and context specific. 

> readResponse enters a loop looking for a non-null statusLine. readStatusLine is
> responsible for setting the variable to a non-null value. If I override
> readStatusLine I cannot set the variable and readResponse is stuck in the loop.
> I cannot override getStatusLine since readResponse uses the variable directly.
> 
> I see four solutions here. Never override readStatusLine (should be private),
> make variable protected, add a setter, or change code to use existing getter.
> Any of the last three will work for me.
> 
> The same problems exist with the other member variables; I just used statusLine
> as an example. I can resubmit the patch for any solution you choose and I can
> ensure that all member variables are accessed in a consistent manner.

My preference would be to make those variables protected. 

HttpMethodBase (imho) is a horrible pile of <self-censored> broken beyond
redemption. I just want to keep it as stable as possible in the 3.x branch and
do away with it in the 4.x branch

Oleg","+1 to make them protected","Created an attachment (id=18025)
Change private member variables to protected.
","Faron,
I think this is too much. Please pprovide a patch with _minimal_ impact on the
existing code. Please make protected only those variables that you absolutely
must have write access to.

Oleg","Faron,

Feel free to re-open the bug if you provide an alternative patch. I am closing
the bug as WONTFIX for now

Oleg","Minimal diff required to override some functionality in child classes","Patch checked in

Oleg"
HTTPCLIENT-705,BUG,BUG,"Handle URIs with path component null",2007-11-16T13:53:47.387+0000,2007-11-19T09:19:45.903+0000,Major,"HttpClient does not handle URIs with path component null (e.g. http://google.com) the same as path component '/'. This results e.g. in a ProtocolException "The server failed to respond with a valid HTTP response".","Fixed in SVN trunk.

Oleg","Thanks"
HTTPCLIENT-738,REFACTORING,BUG,"HostnameVerifier shouldn't shadow simple name of implemented interface",2008-01-31T21:32:32.072+0000,2008-02-04T16:03:19.738+0000,Major,"public interface HostnameVerifier extends javax.net.ssl.HostnameVerifier.

As Findbugs says:

Class names shouldn't shadow simple name of implemented interface

This class/interface has a simple name that is identical to that of an implemented/extended interface, except that the interface is in a different package (e.g., alpha.Foo extends beta.Foo). This can be exceptionally confusing, create lots of situations in which you have to look at import statements to resolve references and creates many opportunities to accidently define methods that do not override methods in their superclasses. 
","Renamed o.a.http.conn.ssl.HostnameVerifier to o.a.http.conn.ssl.X509HostnameVerifier

Oleg"
HTTPCLIENT-99,BUG,BUG,"Requests are retried 3 times unconditionaly",2002-08-14T05:54:39.000+0000,2007-04-22T07:10:06.771+0000,Critical,"Using the 20020811 tarball and jdk1.4.0, a get or post will retry as soon
as it finishes sending the request. I turned on logging and verified that
as soon as the last \r\n hits the wire, it starts on the next retry. For
example:

08-10 09:53:12 [main] httpclient.wire: >> [\r\n]
08-10 09:53:12 [main] httpclient.methods.PostMethod: enter
PostMethod.writeRequestBody(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.write(byte[], int, int)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: Attempt number 3 to write
request
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.writeRequest(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.writeRequestLine(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.generateRequestLine(HttpConnection, String, String, String,
String)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.print(String)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.write(byte[])
08-10 09:53:12 [main] httpclient.wire: >> "POST /lookup.jsp HTTP/1.1" [\r\n]

The top line is the end of the second post and the last line is the start
of the third post.

To make sure the server really wasn't sending something back, I wrote a
quick server that would listen for a request and send a 404 as soon as it
read a post or get line (but would keep reading and dumping info). In the
httpclient log, it still shoots off 3 requests before it receives the
response and the server got all three requests. (client and server are
running on the same machine)

So why is httpclient sending three requests without waiting for a
response?","Thanks to Andrew McCready for identifying this bug.","Created an attachment (id=2704)
Simple fix to HttpMethodBase.java
","Applied the patch and tested.  Request will only be sent once if it is
successful on the first write.

It would be helpful if Andrew McCready could retest with a new nightly tarball
and close this bug if fixed.

","Retested and it works correctly now."
HTTPCLIENT-1142,BUG,BUG,"Infinite loop on NTLM authentication",2011-11-03T14:13:36.985+0000,2011-11-03T16:05:13.589+0000,Major,"I got an infinite loop on NTLM authentication if the authentication failed (bad credentials).

The state FAILED of the NTLM sheme is never catched in the method authenticate of the class HttpAuthenticator (line 123).
I fix temporatily this bug by adding a case for the protocol state HANDSHAKE.","Could you please attach a wire / context log of the failing session [1] as well as your patch? 

Oleg

[1] http://hc.apache.org/httpcomponents-client-dev/logging.html","Find in attachment the logs I have.
You can see that I entered in an infinite loop.

I just added this line before the line 116 : case HANDSHAKE:
It execute the same code than UNCHALLENGED case.

I don't know if it is the best solution ... but it works for me","The fix looks reasonable. Committed to SVN trunk. It is really a shame 4.2a1 got shipped with such a silly one-liner bug.

Oleg"
HTTPCLIENT-1097,SPEC,BUG,"BrowserCompatHostnameVerifier and StrictHostnameVerifier should handle wildcards in SSL certificates better",2011-05-27T20:02:35.278+0000,2011-06-02T13:11:21.054+0000,Minor,"I ran into a problem with SSL wildcard certificates in the class BrowserCompatHostnameVerifier. It handles "*.example.org" fine but "server*.example.org" fails to work correctly. The javadoc claims that it should behave the same way as curl and FireFox. In Firefox an SSL certificate for "server*.example.org" works fine for the host "server.example.org", using HttpClient it throws an exception.

Here is an example test (JUnit4):

package org.example.hb;

import javax.net.ssl.SSLException;

import org.apache.http.conn.ssl.BrowserCompatHostnameVerifier;
import org.junit.Test;

public class BrowserCompatHostnameVerifierTest {

	/**
	 * Should not throw an exeption in the verify method.
	 * @throws SSLException
	 */
	@Test
	public void testVerifyStringStringArrayStringArray() throws SSLException
	{
		BrowserCompatHostnameVerifier hv = new BrowserCompatHostnameVerifier();
		String host = "www.example.org";
		String[] cns = {"www*.example.org"};
		
		hv.verify(host, cns, cns);
	}

}","RFC2818 says this about wildcards:

                                                 Names may contain the wildcard
   character * which is considered to match any single domain name
   component or component fragment. E.g., *.a.com matches foo.a.com but
   not bar.foo.a.com. f*.com matches foo.com but not bar.com.

This implies that the StrictHostnameVerifier ought to allow wildcards for component fragments.

The RFC does not say if *oo.com or f*o.com is allowed - are such certs ever created?
It does appear to disallow multiple wildcards - "... _the_ wildcard character ...".

I assume that the example f*.com is bad, and is not actually allowed!

In which case, wildcards are allowed if:
- there are at least 2 dots, i.e. 3 components
- there is only one *  and this must be at the end of the first component
- if there are 3 components and the last one has two characters then check against bad 2LDs

What about server*.example.com - do curl and Firefox allow this to match server.abc.example.com?

The matching could probably be simplified if this is not allowed.
","Affects AbstractVerifier which is the base for BrowserCompatHostnameVerifier","Better: also affects StrictHostnameVerifier"
HTTPCLIENT-552,RFE,IMPROVEMENT,"Add shutdown method to SimpleHttpConnectionManager",2006-01-14T09:46:41.000+0000,2006-06-14T20:03:39.000+0000,Minor,"It would be useful to be able to close the connection in the
SimpleHttpConnectionManager. This could be achieved by adding a shutdown()
method as per the MultiThreadedConnectionManager.

Ideally this would be added to the HttpConnection interface, but this could
break existing implementations.

To avoid this, perhaps consider introducing a sub-interface with the method in it.

[Could also create an AbstractConnectionManager class - this would make it
easier to add more functions later]","Patch (take 1). Please review

Oleg","I'm not so sure about the HttpConnectionManagerExt interface.  Seems like we should either leave it out and just add the method to SHCM or change the connection manager interface.  My inclination would be for the former.

Mike","Interface extension is not pretty but it is the only way I know of to add new methods to a public interface without breaking the API compatibility. Anyways, let us leave it until 4.0.

Patch (take 2)

Oleg","Sounds good.

Mike","Looks OK to me apart from minor nits:

The copyright on the new interface file says: 1999-2006, which is impossible ... with the current rules it should just be 2006, as I understand it.

shcm.patch says "since 3.1" - should that not be "@since 4.0"  ?
","> shcm.patch says "since 3.1" - should that not be "@since 4.0" ? 

No mistake here. #shutdown() method has been added to the SHCM class and not the HCM interface. This will have to wait until 4.0

Patch checked in

Oleg"
HTTPCLIENT-758,DESIGN_DEFECT,BUG,"Wrong method signatures in AbstractHttpClient",2008-03-10T13:32:16.150+0000,2008-03-10T20:00:04.121+0000,Major,"The method signatures for removeRequestInterceptorByClass and removeResponseInterceptorByClass in AbstractHttpClient are wrong. Must be

public void removeRequestInterceptorByClass(Class<? extends
HttpRequestInterceptor> clazz);

and

public void removeResponseInterceptorByClass(Class<? extends
HttpRequestInterceptor> clazz);","Patch corrects the method signatures to

public void removeRequestInterceptorByClass(Class<? extends HttpRequestInterceptor> clazz);

and

public void removeResponseInterceptorByClass(Class<? extends HttpResponseInterceptor> clazz);","Patch checked in. Many thanks, Johannes

Oleg"
HTTPCLIENT-26,RFE,IMPROVEMENT,"need a way to set request body in PostMethod",2002-04-18T00:02:34.000+0000,2007-04-22T07:09:57.477+0000,Minor,"Currently, there is no way for user to set the request body in PostMethod 
directly. The only way to do that is by adding parameters to PostMethod. This 
makes sense in most cases. However, there are situations that the user actually 
knows the request body and want to set it directly. adding the following method 
fixes this:

    public void setRequestBody(String requestBody)
    {
        this.requestBody = requestBody;
    }","you might also want it to be byte oriented either OutputStream or byte[]. For instance pushing xml 
payload ala SOAP requires byte not String request body. I handled this case by extending 
PostMethod and adding a setBody( byte[] ) and rewrote writeRequestBody which defers to the 
parent when body hasn't been set.","I just added a setRequestBody(String) method to PostMethod.

If someone wants to work on a streaming or file based form, have at it, but you 
may want to consider using PutMethod as the base instead.","*** HTTPCLIENT-36 has been marked as a duplicate of this bug. ***"
HTTPCLIENT-1100,BUG,BUG,"Missing Content-Length header makes cached entry invalid",2011-06-07T14:29:16.121+0000,2011-06-09T15:15:15.694+0000,Major,"A cached entry whose original response didn't carry a Content-Length header, should not be rejected for considered invalid because the length of its cached content is different from the non-existing Content-Length header value. The attached patch only verifies the lengths if the header was originally present.","Hi Bart,

Your patch looks great, although we need you to grant license to the ASF to include your patch. Can you either edit your attachment to grant ASF permission, or re-upload it with the proper permissions?

Thanks,
Jon
","By the way, I suppose this is presumed by my earlier response, but I agree this is a bug. The cache entry should only be considered invalid if there is a Content-Length header present and it does not match the length of the cached response body. If a Content-Length header is not present, then the entry should be presumed valid (at least per the sense of this test).
","with license granted to ASF","Hi Bart, patch applied to trunk. I'll also work on backporting this to the other release branches.
","...and, by the way, Bart, thanks very much for your contribution!
","Also backported to the 4.1.x release branch.
"
HTTPCLIENT-675,BUG,BUG,"thread starving in MultiThreadedHttpConnectionManager",2007-07-26T18:17:25.451+0000,2007-08-11T12:27:45.528+0000,Major,"Hi folks,

I might have found a bug in MTHCM. It has to do with removing HostConnectionPool instances that have no more connections in them. That was a fix for a memory leak we previously had. There are two cases where the pools get deleted. One is in handleLostConnection: (excerpt)
  ...
  if (hostPool.numConnections == 0) mapHosts.remove(config);
  notifyWaitingThread(config);
  ...

Could this delete a pool in which there is still a thread waiting to get a connection? If so, the thread would remain in the global pool. But even if it is interrupted there, it would still use the old HostConnectionPool in which no connection will ever become available again.

I suggest to change the removal check in both cases to:
  if ((hostPool.numConnections < 1) && hostPool.waitingThreads.isEmpty)

What do you think?","please review","If I hear no complaints, I'll commit this patch this week-end.
"
HTTPCLIENT-614,RFE,IMPROVEMENT,"allow different strategies when checking CN of x509 cert",2006-12-08T15:44:31.000+0000,2007-05-21T13:32:40.540+0000,Major,"We're now doing a decent job for checking the CN of the x509 cert with https:

http://issues.apache.org/jira/browse/HTTPCLIENT-613

I think the patch for HTTPCLIENT-613 should cover 99.9% of the users out there.  But there are some more esoteric possibilities, so I think Oleg is right.  We need to let the user change the strategy, or provide their own strategy if they want to. 

Some additional things to think about:

- http://wiki.cacert.org/wiki/VhostTaskForce !!!   CN is depreciated?!?!   (I am not able to find a popular website on HTTPS that isn't using CN!)

- [*.example.com] matches subdomains [a.b.example.com] on Firefox, but not IE6.  The patch for HTTPCLIENT-613 allows subdomains.

- Should we support multiple CN's in the subject?

- Should we support "subjectAltName=DNS:www.example.com" ?  Should we support lots of them in a single cert?

- Should we support a mix of CN and subjectAltName?


If we do create some alternate strategies for people to try, I'd probably lean towards something like this:

X509NameCheckingStrategy.SUN_JAVA_6  (default)
X509NameCheckingStrategy.FIREFOX2
X509NameCheckingStrategy.IE7
X509NameCheckingStrategy.FIRST_CN_AND_NO_WILDCARDS   (aka "STRICT")

","Good point, Julius. Personally I have no experience with SSL on vhosts. But looking at the references document it looks like we should support the "CN+SubjAltNames" and "SubjectAltName" variants.

May I mention that the * solution in 613 is wrong:
if ( wildcard )     match = host.endsWith( cn.substring( 1 ) );
would result in bar.foo.a.com matching *.a.com
but RFC says:
E.g., *.a.com matches foo.a.com but  not bar.foo.a.com. 

Making a mistake here opens spoofing possibilities!","Hi, Odi,

I believe "host.endsWith( cn.substring( 1 ) )" mimics Firefox's behaviour  (but without support for "CN + SubjAltNames").

This wiki entry has an interesting catalog of browser behaviour with wildcards:

http://wiki.cacert.org/wiki/WildcardCertificates

- IE6 doesn't allow subdomains (so follows the RFC).   *.apache.org  does not match  "a.b.apache.org".

- Firefox/Mozilla allows subdomains (breaks RFC).    *.apache.org  DOES MATCH  "a.b.apache.org"!

- New versions of Konqueror (so Safari too?) allows subdomains (breaks RFC).

- Opera 9.0 allows subdomains (breaks RFC).


I think I'll do some experimentation on my own and test some additional clients.  I'll add my findings to cacert's very handy wiki!  Curious about the following (but I'm lazy so I'm just going to stick to Linux and maybe a little dabbling on Windows):

- wget
- curl
- java.net.URL on the following:
   1.  Sun Java 1.3.1 + JSSE  
   2.  Sun Java 1.4.2
   3.  Sun Java 5.0
   4.  Sun Java 6.0
   5.  IBM Java 1.4.2
   6.  IBM Java 5.0
   7.  JRockit Java 1.4.2
   8.  JRockit Java 5.0

I think if our default behaviour mimics Sun Java 6, that's good enough.

","Julius,
We have been through a similar process with HTTP cookie policies. Pluggable validators is the way to go. Anyone who needs a specific way of validating host names is very welcome to build his/her own.  We should provide two policies (validators) out of the box: the RFC compliant (strict) and the browser compatible  (lapse). No need to mimic every single bloody browser out there.

Oleg","Trying out a pluggable implementation.

If anyone is interested in seeing where I'm currently at:

http://juliusdavies.ca/httpclient/

Of note:

New interface:
o.a.http.conn.ssl.HostnameVerifier

It actually extends the javax.net.ssl one (http://java.sun.com/j2se/1.5.0/docs/api/javax/net/ssl/HostnameVerifier.html).  But I don't expect our SSLSocketFactory to use that API.  I'm just including that as a comforting "things seem familiar" door-knob/hand-rail.

Of note, I'm actually sticking the implementation directly inside this interface as anonymous-inner-classes.  Defining the following:

HostnameVerifier.DEFAULT  (mimics curl and firefox)
HostnameVerifier.STRICT  (mimics java.net.URL, and very close to IE6)
HostnameVerifier.ALLOW_ALL  (turns off hostname verification)

IIRC, anonymous inner-classes only showed up in Java 1.3.x so this would be inappropriate for Httpclient 3.x (which supports Java 1.2.x).

Now I'm just working on unit tests before I create the patch....

","This patch introduces a pluggable HostnameVerifer implementation, including JUnit tests.  I also threw in two other things:

#1.   Use HttpsURLConnection.getDefaultSSLSocketFactory().
------------------------------------
the no-arg SSLSocketFactory() constructor now uses:
HttpsURLConnection.getDefaultSSLSocketFactory();

This way the client certs in the browser will also be available when using Java Webstart, and brings our "https" behaviour even closer to java.net.URL's.


#2.  JUnits for SSLSocketFactory
------------------------------------
JUnit dependency on commons-codec.  This is so I can decode a base64 RSA private key I stored inside "CertificatesToPlayWith".  Probably I should unravel that and just store the BigIntegers directly, and get rid of the commons-codec dependency.

This RSA private key is important so that we can build our own JKS, store it using a temp file, set the "javax.net.ssl.keystore" system property, and become our own SSLServer in a reliable and repeatable way.  We also set the "javax.net.ssl.truststore" system property to point to the same temp file so that we can make sure HttpsURLConnection.getDefaultSSLSocketFactory() isn't stabbing us in the back!

All JUnit tests are passing on Linux with:

Sun 1.4.2
Sun 5.0
Sun 6.0-rc
IBM 1.4.2
IBM 5.0

","Julius,

Would it be possible to get rid of dependency on commons-codec, especially if it is only needed to run test cases? 

I personally would prefer to move all HostnameVerifier impls to o.a.http.conn.impl package. HostnameVerifier.DEFAULT and friends should probably be better off moved to an object factory of a sort.

I'll review the patch more thoroughly tomorrow and check it in to the SVN trunk

Oleg","- this patch is better: removed dependency on commons-codec

- no longer accidentally including setTimeout() in DefaultHttpHostConnection.java (required for javac, though!)



","- No more japanese characters directly in the source files.  Using "\u82b1\u5b50" instead.  These japanese hostname tests are probably silly (will never occur in real life thanks to ""xn--i8s592g.co.jp" puny encoding.  But they're fun.  :-)

Oleg, can we commit this version, and then look into a factory approach?","Julius, 

I'll review and commit the patch later tonight or tomorrow in the evening

Oleg","Patch checked in. Many thanks, Julius

Oleg","* Moved all concrete HostnameVerifier impls from the interface declaration to separate public classes
* Renamed DEFAULT HostnameVerifier to BROWSER_COMPATIBLE (still used per default, but we may want to use STRICT instead in the future)

Closing as FIXED. Many thanks for this contribution, Julius 

Oleg"
HTTPCLIENT-713,CLEANUP,